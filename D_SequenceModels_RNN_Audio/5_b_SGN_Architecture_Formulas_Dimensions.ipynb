{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab8ceda",
   "metadata": {},
   "source": [
    "# SGN Architecture: Mathematical Formulation and Dimension Analysis\n",
    "\n",
    "## Overview\n",
    "This document provides complete mathematical formulation of the SGN (Speech Enhancement Network) model for multi-microphone Echo Cancellation (EC) and Noise Suppression (NS).\n",
    "\n",
    "**Model Configuration (15.x - 2 mic SGN+EC+NS):**\n",
    "- Window size: 20ms (sine window)\n",
    "- Hop size: 10ms (50% overlap)\n",
    "- FFT size: 320\n",
    "- Delay: 20ms (2 frames lookback)\n",
    "- Memory: 5.5M parameters\n",
    "- Complexity: ~0.5 GMAC/s\n",
    "\n",
    "---\n",
    "\n",
    "## 1. STFT Preprocessing\n",
    "\n",
    "### 1.1 Short-Time Fourier Transform\n",
    "\n",
    "**Input:** Time-domain signals from 2 microphones and reference\n",
    "- $x_1(n)$: Microphone 1 signal, $n \\in [0, N-1]$\n",
    "- $x_2(n)$: Microphone 2 signal\n",
    "- $r(n)$: Reference signal (for echo cancellation)\n",
    "\n",
    "**Windowing:**\n",
    "$$w(n) = \\sin\\left(\\frac{\\pi(n + 0.5)}{L}\\right), \\quad n \\in [0, L-1]$$\n",
    "\n",
    "where $L = 320$ (20ms at 16kHz sampling rate)\n",
    "\n",
    "**STFT Computation:**\n",
    "$$X_m(k, f) = \\sum_{n=0}^{L-1} x_m(n + kH) \\cdot w(n) \\cdot e^{-j2\\pi fn/L}$$\n",
    "\n",
    "where:\n",
    "- $m \\in \\{1, 2\\}$: microphone index\n",
    "- $k$: frame index\n",
    "- $f \\in [0, 159]$: frequency bin (using only positive frequencies)\n",
    "- $H = 160$: hop size (10ms)\n",
    "\n",
    "**Magnitude and Phase:**\n",
    "$$|X_m(k, f)| = \\sqrt{\\text{Re}(X_m(k,f))^2 + \\text{Im}(X_m(k,f))^2}$$\n",
    "$$\\angle X_m(k, f) = \\arctan\\left(\\frac{\\text{Im}(X_m(k,f))}{\\text{Re}(X_m(k,f))}\\right)$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $[B, T]$ where $B$ = batch size, $T$ = time samples\n",
    "- After STFT: $[B, K, F]$ where $K$ = number of frames, $F = 161$ frequency bins\n",
    "- Network uses: $[B, K, 320]$ (concatenating real and imaginary parts)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Pre-processing Layer\n",
    "\n",
    "### 2.1 FFT Layer\n",
    "Converts time-domain to frequency-domain representation.\n",
    "\n",
    "**Input dimensions:** $[B, 1, 160]$ per microphone\n",
    "**Output dimensions:** $[B, 1, 161]$ (magnitude spectrum)\n",
    "\n",
    "For 2 microphones:\n",
    "$$\\mathbf{X}_{\\text{pre}} = [\\mathbf{X}_1; \\mathbf{X}_2] \\in \\mathbb{R}^{B \\times 2 \\times 161}$$\n",
    "\n",
    "### 2.2 Pre-processing Transformation\n",
    "$$\\mathbf{X}_{\\text{proc}} = \\text{PreProc}(\\mathbf{X}_{\\text{pre}}) \\in \\mathbb{R}^{B \\times 2 \\times 320}$$\n",
    "\n",
    "This doubles the feature dimension to 320 (likely concatenating magnitude and phase or real/imaginary components).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Rotation Layer\n",
    "\n",
    "### 3.1 Purpose\n",
    "The Rotation layer performs a **learnable linear transformation** that:\n",
    "1. Mixes spatial information from multiple microphones\n",
    "2. Projects to higher-dimensional feature space\n",
    "3. Acts as data-driven beamforming\n",
    "4. Enhances feature separability\n",
    "\n",
    "### 3.2 Mathematical Formulation\n",
    "\n",
    "**Weight Matrix:**\n",
    "$$\\mathbf{W}_{\\text{rot}} \\in \\mathbb{R}^{640 \\times 640}$$\n",
    "\n",
    "**Bias Vector:**\n",
    "$$\\mathbf{b}_{\\text{rot}} \\in \\mathbb{R}^{640}$$\n",
    "\n",
    "**Forward Pass:**\n",
    "$$\\mathbf{Y}_{\\text{rot}} = \\mathbf{W}_{\\text{rot}} \\cdot \\mathbf{X}_{\\text{concat}} + \\mathbf{b}_{\\text{rot}}$$\n",
    "\n",
    "where $\\mathbf{X}_{\\text{concat}} \\in \\mathbb{R}^{B \\times 640}$ is the concatenated input from 2 mics (each 320-dim).\n",
    "\n",
    "**Dimension Transformation:**\n",
    "$$[B, 2, 320] \\xrightarrow{\\text{reshape}} [B, 640] \\xrightarrow{\\text{Linear}} [B, 640] \\xrightarrow{\\text{reshape}} [B, 8, 640]$$\n",
    "\n",
    "Wait, let me recalculate based on the architecture diagram...\n",
    "\n",
    "**Corrected Dimensions (from diagram):**\n",
    "- Input: 2 microphones × 320 features = $[B, 2 \\times 320]$\n",
    "- Output: 8 channels × 640 features = $[B, 8, 640]$\n",
    "\n",
    "Actually, the rotation layer output is $8 \\times 640$, so:\n",
    "\n",
    "$$\\mathbf{Y}_{\\text{rot}} \\in \\mathbb{R}^{B \\times 8 \\times 640}$$\n",
    "\n",
    "The transformation can be viewed as:\n",
    "$$\\mathbf{Y}_{\\text{rot}}[b, c, :] = \\mathbf{W}_{\\text{rot}}^{(c)} \\cdot \\mathbf{X}_{\\text{flat}}[b, :] + \\mathbf{b}_{\\text{rot}}^{(c)}$$\n",
    "\n",
    "where:\n",
    "- $c \\in [0, 7]$: output channel index\n",
    "- $\\mathbf{W}_{\\text{rot}}^{(c)} \\in \\mathbb{R}^{640 \\times 640}$\n",
    "- $\\mathbf{X}_{\\text{flat}}[b, :] \\in \\mathbb{R}^{640}$ (flattened 2×320 input)\n",
    "\n",
    "### 3.3 Why Rotation Helps\n",
    "\n",
    "**Spatial Feature Mixing:**\n",
    "$$\\mathbf{Y}_{\\text{rot}}[i] = \\sum_{j=1}^{640} w_{ij} \\cdot \\mathbf{X}[j]$$\n",
    "\n",
    "This creates **linear combinations** of features from both microphones, similar to:\n",
    "- **Beamforming:** $y = \\sum_m w_m \\cdot x_m$ (weighted sum of mic signals)\n",
    "- **ICA/PCA:** Finding optimal projections for source separation\n",
    "\n",
    "**Learned vs Traditional Beamforming:**\n",
    "- Traditional: $\\mathbf{w}$ computed from geometry/statistics\n",
    "- SGN Rotation: $\\mathbf{W}_{\\text{rot}}$ learned from data to maximize noise suppression\n",
    "\n",
    "### 3.4 Gradient Flow (Backpropagation)\n",
    "\n",
    "**Loss gradient w.r.t. output:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}} \\in \\mathbb{R}^{B \\times 8 \\times 640}$$\n",
    "\n",
    "**Gradient w.r.t. weights:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{\\text{rot}}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}} \\cdot \\mathbf{X}_{\\text{flat}}^T$$\n",
    "\n",
    "**Gradient w.r.t. input:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}_{\\text{flat}}} = \\mathbf{W}_{\\text{rot}}^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Concatenation with Delayed Reference\n",
    "\n",
    "### 4.1 Delay Operation\n",
    "\n",
    "**Reference Signal STFT:**\n",
    "$$\\mathbf{R}(k, f) = \\text{STFT}(r(n))$$\n",
    "\n",
    "**Delayed Reference (2 frames = 20ms lookback):**\n",
    "$$\\mathbf{R}_{\\text{delayed}}(k) = [\\mathbf{R}(k-2), \\mathbf{R}(k-1)]$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Current rotated features: $[B, 8, 640]$\n",
    "- Delayed reference: $[B, 8, 960]$ (includes 2 past frames)\n",
    "\n",
    "### 4.2 Concatenation\n",
    "\n",
    "$$\\mathbf{Z} = [\\mathbf{Y}_{\\text{rot}}; \\mathbf{R}_{\\text{delayed}}] \\in \\mathbb{R}^{B \\times 8 \\times 1280}$$\n",
    "\n",
    "**Why Concatenation Helps:**\n",
    "- Provides **echo path information** for cancellation\n",
    "- Temporal alignment accounts for acoustic delay\n",
    "- Enables prediction of echo component: $\\hat{e}(k) = f(\\mathbf{R}(k-2), \\mathbf{R}(k-1))$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Bidirectional LSTM (BiLSTM)\n",
    "\n",
    "### 5.1 LSTM Cell Equations\n",
    "\n",
    "**Forward LSTM at time $t$:**\n",
    "\n",
    "**Forget Gate:**\n",
    "$$\\mathbf{f}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_f^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_f^{(\\rightarrow)})$$\n",
    "\n",
    "**Input Gate:**\n",
    "$$\\mathbf{i}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_i^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_i^{(\\rightarrow)})$$\n",
    "\n",
    "**Cell Candidate:**\n",
    "$$\\tilde{\\mathbf{c}}_t^{(\\rightarrow)} = \\tanh(\\mathbf{W}_c^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_c^{(\\rightarrow)})$$\n",
    "\n",
    "**Cell State Update:**\n",
    "$$\\mathbf{c}_t^{(\\rightarrow)} = \\mathbf{f}_t^{(\\rightarrow)} \\odot \\mathbf{c}_{t-1}^{(\\rightarrow)} + \\mathbf{i}_t^{(\\rightarrow)} \\odot \\tilde{\\mathbf{c}}_t^{(\\rightarrow)}$$\n",
    "\n",
    "**Output Gate:**\n",
    "$$\\mathbf{o}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_o^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_o^{(\\rightarrow)})$$\n",
    "\n",
    "**Hidden State:**\n",
    "$$\\mathbf{h}_t^{(\\rightarrow)} = \\mathbf{o}_t^{(\\rightarrow)} \\odot \\tanh(\\mathbf{c}_t^{(\\rightarrow)})$$\n",
    "\n",
    "**Backward LSTM** (processes sequence in reverse):\n",
    "$$\\mathbf{h}_t^{(\\leftarrow)} = \\text{LSTM}^{(\\leftarrow)}(\\mathbf{z}_t, \\mathbf{h}_{t+1}^{(\\leftarrow)})$$\n",
    "\n",
    "### 5.2 BiLSTM Output\n",
    "\n",
    "**Concatenation of forward and backward:**\n",
    "$$\\mathbf{h}_t^{\\text{bi}} = [\\mathbf{h}_t^{(\\rightarrow)}; \\mathbf{h}_t^{(\\leftarrow)}]$$\n",
    "\n",
    "**Dimension Transformation:**\n",
    "- Input: $\\mathbf{z}_t \\in \\mathbb{R}^{8 \\times 1280}$\n",
    "- Forward hidden: $\\mathbf{h}_t^{(\\rightarrow)} \\in \\mathbb{R}^{8 \\times 160}$\n",
    "- Backward hidden: $\\mathbf{h}_t^{(\\leftarrow)} \\in \\mathbb{R}^{8 \\times 160}$\n",
    "- BiLSTM output: $\\mathbf{h}_t^{\\text{bi}} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 5.3 Why BiLSTM Helps\n",
    "\n",
    "**Temporal Context:**\n",
    "- Forward LSTM: Captures past context $\\mathbf{h}_t^{(\\rightarrow)} = f(\\mathbf{z}_1, ..., \\mathbf{z}_t)$\n",
    "- Backward LSTM: Captures future context $\\mathbf{h}_t^{(\\leftarrow)} = f(\\mathbf{z}_T, ..., \\mathbf{z}_t)$\n",
    "- Combined: Full temporal context $\\mathbf{h}_t^{\\text{bi}} = f(\\mathbf{z}_1, ..., \\mathbf{z}_T)$\n",
    "\n",
    "**Benefits for Noise Suppression:**\n",
    "1. **Non-stationary noise tracking:** Adapts to time-varying noise\n",
    "2. **Speech continuity:** Uses future frames to better estimate current frame\n",
    "3. **Echo path modeling:** Tracks time-varying acoustic paths\n",
    "\n",
    "---\n",
    "\n",
    "## 6. LSTM Branches (×2)\n",
    "\n",
    "### 6.1 Dual Branch Architecture\n",
    "\n",
    "**Branch 1 (likely for Echo Cancellation):**\n",
    "$$\\mathbf{h}_t^{(1)} = \\text{LSTM}_1(\\mathbf{h}_t^{\\text{bi}}, \\mathbf{h}_{t-1}^{(1)})$$\n",
    "\n",
    "**Branch 2 (likely for Noise Suppression):**\n",
    "$$\\mathbf{h}_t^{(2)} = \\text{LSTM}_2(\\mathbf{h}_t^{\\text{bi}}, \\mathbf{h}_{t-1}^{(2)})$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input to each branch: $\\mathbf{h}_t^{\\text{bi}} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Output from each branch: $\\mathbf{h}_t^{(i)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 6.2 LSTM Cell (Standard)\n",
    "\n",
    "Each branch uses standard LSTM equations (same as BiLSTM but unidirectional):\n",
    "\n",
    "$$\\mathbf{f}_t = \\sigma(\\mathbf{W}_f \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_f)$$\n",
    "$$\\mathbf{i}_t = \\sigma(\\mathbf{W}_i \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_i)$$\n",
    "$$\\tilde{\\mathbf{c}}_t = \\tanh(\\mathbf{W}_c \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_c)$$\n",
    "$$\\mathbf{c}_t = \\mathbf{f}_t \\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t \\odot \\tilde{\\mathbf{c}}_t$$\n",
    "$$\\mathbf{o}_t = \\sigma(\\mathbf{W}_o \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_o)$$\n",
    "$$\\mathbf{h}_t = \\mathbf{o}_t \\odot \\tanh(\\mathbf{c}_t)$$\n",
    "\n",
    "### 6.3 Why Dual Branches Help\n",
    "\n",
    "**Task Decomposition:**\n",
    "- **Branch 1 specialization:** Learns echo-specific patterns\n",
    "  - Echo is correlated with reference signal\n",
    "  - Requires modeling linear/non-linear echo paths\n",
    "  \n",
    "- **Branch 2 specialization:** Learns noise-specific patterns\n",
    "  - Noise is uncorrelated with reference\n",
    "  - Requires statistical noise modeling\n",
    "\n",
    "**Mathematical Intuition:**\n",
    "$$\\mathbf{y}_{\\text{noisy}} = \\mathbf{s}_{\\text{clean}} + \\mathbf{e}_{\\text{echo}} + \\mathbf{n}_{\\text{noise}}$$\n",
    "\n",
    "- Branch 1 estimates: $\\hat{\\mathbf{e}}_{\\text{echo}}$\n",
    "- Branch 2 estimates: $\\hat{\\mathbf{n}}_{\\text{noise}}$\n",
    "- Combined: $\\hat{\\mathbf{s}}_{\\text{clean}} = \\mathbf{y}_{\\text{noisy}} - \\hat{\\mathbf{e}}_{\\text{echo}} - \\hat{\\mathbf{n}}_{\\text{noise}}$\n",
    "\n",
    "**Multi-task Learning Benefit:**\n",
    "- Shared BiLSTM learns common representations\n",
    "- Separate branches learn task-specific features\n",
    "- Prevents interference between EC and NS objectives\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Fully Connected (FC) Layers\n",
    "\n",
    "### 7.1 FC Layer 1 (after Branch 1)\n",
    "\n",
    "**Linear Transformation:**\n",
    "$$\\mathbf{y}_1 = \\mathbf{W}_1 \\cdot \\mathbf{h}^{(1)} + \\mathbf{b}_1$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $\\mathbf{h}^{(1)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Weights: $\\mathbf{W}_1 \\in \\mathbb{R}^{640 \\times 320}$\n",
    "- Output: $\\mathbf{y}_1 \\in \\mathbb{R}^{8 \\times 640}$\n",
    "\n",
    "**Activation (typically ReLU or none):**\n",
    "$$\\mathbf{y}_1 = \\max(0, \\mathbf{W}_1 \\cdot \\mathbf{h}^{(1)} + \\mathbf{b}_1)$$\n",
    "\n",
    "### 7.2 FC Layer 2 (after Branch 2)\n",
    "\n",
    "**Linear Transformation:**\n",
    "$$\\mathbf{y}_2 = \\mathbf{W}_2 \\cdot \\mathbf{h}^{(2)} + \\mathbf{b}_2$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $\\mathbf{h}^{(2)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Weights: $\\mathbf{W}_2 \\in \\mathbb{R}^{320 \\times 320}$\n",
    "- Output: $\\mathbf{y}_2 \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 7.3 Why FC Layers Help\n",
    "\n",
    "**Non-linear Mapping:**\n",
    "- Maps LSTM features to mask/gain space\n",
    "- Learns complex relationships: $\\text{Mask} = f_{\\text{FC}}(\\text{LSTM features})$\n",
    "\n",
    "**Dimension Matching:**\n",
    "- Ensures outputs match for combination\n",
    "- FC1 expands: $320 \\rightarrow 640$ (more capacity)\n",
    "- FC2 maintains: $320 \\rightarrow 320$ (refinement)\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Filter Block (Mask Generation)\n",
    "\n",
    "### 8.1 Feature Combination\n",
    "\n",
    "**Concatenation or Addition:**\n",
    "$$\\mathbf{y}_{\\text{combined}} = [\\mathbf{y}_1; \\mathbf{y}_2] \\quad \\text{or} \\quad \\mathbf{y}_{\\text{combined}} = \\mathbf{y}_1 + \\mathbf{y}_2$$\n",
    "\n",
    "Based on diagram (⊕ symbol), likely addition after dimension matching:\n",
    "$$\\mathbf{y}_{\\text{combined}} = \\mathbf{y}_1[:, :320] + \\mathbf{y}_2 \\in \\mathbb{R}^{8 \\times 320}$$\n",
    "\n",
    "### 8.2 Mask Computation\n",
    "\n",
    "**Final FC Layer:**\n",
    "$$\\mathbf{m}_{\\text{logits}} = \\mathbf{W}_{\\text{mask}} \\cdot \\mathbf{y}_{\\text{combined}} + \\mathbf{b}_{\\text{mask}}$$\n",
    "\n",
    "**Sigmoid Activation (for gain mask):**\n",
    "$$\\mathbf{M}(k, f) = \\sigma(\\mathbf{m}_{\\text{logits}}(k, f)) = \\frac{1}{1 + e^{-\\mathbf{m}_{\\text{logits}}(k, f)}}$$\n",
    "\n",
    "where $\\mathbf{M}(k, f) \\in [0, 1]$ is the gain mask for frame $k$, frequency $f$.\n",
    "\n",
    "**Alternative: Softmax (for ratio mask):**\n",
    "$$\\mathbf{M}_{\\text{speech}}(k, f) = \\frac{e^{\\mathbf{m}_{\\text{speech}}(k, f)}}{e^{\\mathbf{m}_{\\text{speech}}(k, f)} + e^{\\mathbf{m}_{\\text{noise}}(k, f)}}$$\n",
    "\n",
    "### 8.3 Adaptive Filtering\n",
    "\n",
    "**Apply Mask to Noisy Spectrum:**\n",
    "$$\\hat{\\mathbf{S}}_{\\text{clean}}(k, f) = \\mathbf{M}(k, f) \\cdot \\mathbf{X}_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**Element-wise multiplication:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = M(k, f) \\times X_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**In complex domain:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = M(k, f) \\times |X_{\\text{noisy}}(k, f)| \\times e^{j\\angle X_{\\text{noisy}}(k, f)}$$\n",
    "\n",
    "### 8.4 Why Adaptive Filtering Works\n",
    "\n",
    "**Frequency-Selective Suppression:**\n",
    "- Each frequency bin has independent gain $M(k, f)$\n",
    "- Suppresses noise-dominated bins: $M(k, f) \\approx 0$\n",
    "- Preserves speech-dominated bins: $M(k, f) \\approx 1$\n",
    "\n",
    "**Comparison to Wiener Filter:**\n",
    "\n",
    "Traditional Wiener filter:\n",
    "$$M_{\\text{Wiener}}(k, f) = \\frac{|S(k, f)|^2}{|S(k, f)|^2 + |N(k, f)|^2}$$\n",
    "\n",
    "SGN learned mask:\n",
    "$$M_{\\text{SGN}}(k, f) = \\sigma(\\text{NN}(\\mathbf{X}_{\\text{noisy}}, \\mathbf{R}_{\\text{ref}}))$$\n",
    "\n",
    "**Advantages of learned mask:**\n",
    "1. Non-linear: Can model complex noise patterns\n",
    "2. Context-aware: Uses temporal context from LSTM\n",
    "3. Multi-microphone: Leverages spatial information\n",
    "4. Adaptive: Learns from data, not assumptions\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Inverse STFT (Post-processing)\n",
    "\n",
    "### 9.1 Inverse FFT\n",
    "\n",
    "**Reconstruct Complex Spectrum:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = |\\hat{S}_{\\text{clean}}(k, f)| \\times e^{j\\angle X_{\\text{noisy}}(k, f)}$$\n",
    "\n",
    "(Phase is typically preserved from noisy signal)\n",
    "\n",
    "**Inverse FFT:**\n",
    "$$\\hat{s}_{\\text{clean}}(n + kH) = \\text{IFFT}(\\hat{S}_{\\text{clean}}(k, :))$$\n",
    "\n",
    "### 9.2 Overlap-Add\n",
    "\n",
    "**Windowing:**\n",
    "$$\\hat{s}_{\\text{windowed}}(n + kH) = \\hat{s}_{\\text{clean}}(n + kH) \\times w(n)$$\n",
    "\n",
    "**Overlap-Add Reconstruction:**\n",
    "$$\\hat{s}_{\\text{output}}(n) = \\sum_{k} \\hat{s}_{\\text{windowed}}(n - kH)$$\n",
    "\n",
    "**Normalization (for 50% overlap):**\n",
    "$$\\hat{s}_{\\text{output}}(n) = \\frac{\\sum_{k} \\hat{s}_{\\text{windowed}}(n - kH)}{\\sum_{k} w^2(n - kH)}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Loss Function\n",
    "\n",
    "### 10.1 Time-Domain Loss (MSE)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{time}} = \\frac{1}{N} \\sum_{n=1}^{N} (\\hat{s}_{\\text{clean}}(n) - s_{\\text{target}}(n))^2$$\n",
    "\n",
    "### 10.2 Frequency-Domain Loss (MSE on Magnitude)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{freq}} = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} (|\\hat{S}_{\\text{clean}}(k, f)| - |S_{\\text{target}}(k, f)|)^2$$\n",
    "\n",
    "### 10.3 Perceptual Loss (SI-SNR)\n",
    "\n",
    "**Scale-Invariant SNR:**\n",
    "$$\\text{SI-SNR} = 10 \\log_{10} \\frac{\\|\\alpha s_{\\text{target}}\\|^2}{\\|\\alpha s_{\\text{target}} - \\hat{s}_{\\text{clean}}\\|^2}$$\n",
    "\n",
    "where $\\alpha = \\frac{\\langle \\hat{s}_{\\text{clean}}, s_{\\text{target}} \\rangle}{\\|s_{\\text{target}}\\|^2}$\n",
    "\n",
    "**Loss:**\n",
    "$$\\mathcal{L}_{\\text{SI-SNR}} = -\\text{SI-SNR}$$\n",
    "\n",
    "### 10.4 Combined Loss\n",
    "\n",
    "$$\\mathcal{L}_{\\text{total}} = \\lambda_1 \\mathcal{L}_{\\text{time}} + \\lambda_2 \\mathcal{L}_{\\text{freq}} + \\lambda_3 \\mathcal{L}_{\\text{SI-SNR}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Backpropagation Through Time (BPTT)\n",
    "\n",
    "### 11.1 Gradient Flow\n",
    "\n",
    "**Loss gradient w.r.t. mask:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{M}(k, f)} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{S}(k, f)} \\cdot X_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**Gradient through sigmoid:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{m}_{\\text{logits}}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{M}} \\cdot \\mathbf{M} \\cdot (1 - \\mathbf{M})$$\n",
    "\n",
    "**Gradient through FC layers:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_i} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}_i} \\cdot \\mathbf{h}^{(i)T}$$\n",
    "\n",
    "### 11.2 LSTM Gradient\n",
    "\n",
    "**Gradient through LSTM cell:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}_t} + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{t+1}} \\cdot \\frac{\\partial \\mathbf{h}_{t+1}}{\\partial \\mathbf{h}_t}$$\n",
    "\n",
    "**Cell state gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} \\cdot \\mathbf{o}_t \\cdot (1 - \\tanh^2(\\mathbf{c}_t)) + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_{t+1}} \\cdot \\mathbf{f}_{t+1}$$\n",
    "\n",
    "**Gate gradients:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{f}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t} \\cdot \\mathbf{c}_{t-1} \\cdot \\mathbf{f}_t \\cdot (1 - \\mathbf{f}_t)$$\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Parameter Count Analysis\n",
    "\n",
    "### 12.1 Layer-wise Parameters\n",
    "\n",
    "**Rotation Layer:**\n",
    "- Weights: $640 \\times 640 = 409,600$\n",
    "- Bias: $640$\n",
    "- Total: **409,640**\n",
    "\n",
    "**BiLSTM:**\n",
    "- Forward LSTM: $4 \\times (320 \\times (1280 + 160) + 160) = 4 \\times 461,600 = 1,846,400$\n",
    "- Backward LSTM: $1,846,400$\n",
    "- Total: **3,692,800**\n",
    "\n",
    "**LSTM Branch 1:**\n",
    "- Parameters: $4 \\times (320 \\times (320 + 320) + 320) = 4 \\times 205,120 = 820,480$\n",
    "- Total: **820,480**\n",
    "\n",
    "**LSTM Branch 2:**\n",
    "- Parameters: **820,480**\n",
    "\n",
    "**FC Layers:**\n",
    "- FC1: $640 \\times 320 + 640 = 205,440$\n",
    "- FC2: $320 \\times 320 + 320 = 102,720$\n",
    "- Total: **308,160**\n",
    "\n",
    "**Total Parameters:**\n",
    "$$409,640 + 3,692,800 + 820,480 + 820,480 + 308,160 = 6,051,560 \\approx 6M$$\n",
    "\n",
    "(Close to stated 5.5M, difference may be in exact architecture details)\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Computational Complexity\n",
    "\n",
    "### 13.1 FLOPs per Frame\n",
    "\n",
    "**STFT/ISTFT:**\n",
    "- FFT: $O(F \\log F) = O(320 \\log 320) \\approx 2,560$ FLOPs\n",
    "\n",
    "**Rotation Layer:**\n",
    "- Matrix multiply: $640 \\times 640 = 409,600$ FLOPs\n",
    "\n",
    "**BiLSTM:**\n",
    "- Forward: $4 \\times 320 \\times 1440 = 1,843,200$ FLOPs\n",
    "- Backward: $1,843,200$ FLOPs\n",
    "- Total: $3,686,400$ FLOPs\n",
    "\n",
    "**LSTM Branches:**\n",
    "- Branch 1: $4 \\times 320 \\times 640 = 819,200$ FLOPs\n",
    "- Branch 2: $819,200$ FLOPs\n",
    "- Total: $1,638,400$ FLOPs\n",
    "\n",
    "**FC Layers:**\n",
    "- FC1: $640 \\times 320 = 204,800$ FLOPs\n",
    "- FC2: $320 \\times 320 = 102,400$ FLOPs\n",
    "- Total: $307,200$ FLOPs\n",
    "\n",
    "**Total per frame:**\n",
    "$$2,560 + 409,600 + 3,686,400 + 1,638,400 + 307,200 = 6,044,160 \\approx 6M \\text{ FLOPs}$$\n",
    "\n",
    "**At 100 fps (10ms hop):**\n",
    "$$6M \\times 100 = 600M \\text{ FLOPs/s} = 0.6 \\text{ GFLOPS} \\approx 0.5 \\text{ GMAC/s}$$\n",
    "\n",
    "(Matches stated complexity)\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Summary of Dimension Flow\n",
    "\n",
    "```\n",
    "Input Audio (2 mics + ref):\n",
    "  [B, T] × 3\n",
    "\n",
    "↓ STFT\n",
    "\n",
    "Spectrograms:\n",
    "  [B, K, 161] × 3\n",
    "\n",
    "↓ Pre-processing\n",
    "\n",
    "Features:\n",
    "  [B, K, 2, 320]\n",
    "\n",
    "↓ Rotation Layer\n",
    "\n",
    "Rotated Features:\n",
    "  [B, K, 8, 640]\n",
    "\n",
    "↓ Concat with Delayed Ref\n",
    "\n",
    "Combined:\n",
    "  [B, K, 8, 1280]\n",
    "\n",
    "↓ BiLSTM\n",
    "\n",
    "Temporal Features:\n",
    "  [B, K, 8, 320]\n",
    "\n",
    "↓ Dual LSTM Branches\n",
    "\n",
    "Branch 1: [B, K, 8, 320]\n",
    "Branch 2: [B, K, 8, 320]\n",
    "\n",
    "↓ FC Layers\n",
    "\n",
    "FC1 out: [B, K, 8, 640]\n",
    "FC2 out: [B, K, 8, 320]\n",
    "\n",
    "↓ Combine + Filter\n",
    "\n",
    "Mask:\n",
    "  [B, K, 161]\n",
    "\n",
    "↓ Apply Mask\n",
    "\n",
    "Clean Spectrum:\n",
    "  [B, K, 161]\n",
    "\n",
    "↓ ISTFT\n",
    "\n",
    "Output Audio:\n",
    "  [B, T]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15. Key Takeaways\n",
    "\n",
    "1. **Rotation Layer** = Learned beamforming (spatial mixing)\n",
    "2. **BiLSTM** = Temporal context (past + future)\n",
    "3. **Dual Branches** = Task decomposition (EC + NS)\n",
    "4. **FC Layers** = Non-linear mapping to mask space\n",
    "5. **Adaptive Filtering** = Frequency-selective suppression\n",
    "\n",
    "**Why SGN Works:**\n",
    "- Combines spatial (multi-mic) and temporal (LSTM) processing\n",
    "- Learns optimal features for noise suppression\n",
    "- Adapts to non-stationary noise and echo\n",
    "- Efficient: Only 5.5M params, 0.5 GMAC/s\n",
    "\n",
    "---\n",
    "\n",
    "*End of Mathematical Formulation*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562c314",
   "metadata": {},
   "source": [
    "# SGN Architecture: Mathematical Formulation and Dimension Analysis\n",
    "\n",
    "## Overview\n",
    "This document provides complete mathematical formulation of the SGN (Speech Enhancement Network) model for multi-microphone Echo Cancellation (EC) and Noise Suppression (NS).\n",
    "\n",
    "**Model Configuration (15.x - 2 mic SGN+EC+NS):**\n",
    "- Window size: 20ms (sine window)\n",
    "- Hop size: 10ms (50% overlap)\n",
    "- FFT size: 320\n",
    "- Delay: 20ms (2 frames lookback)\n",
    "- Memory: 5.5M parameters\n",
    "- Complexity: ~0.5 GMAC/s\n",
    "\n",
    "---\n",
    "\n",
    "## 1. STFT Preprocessing\n",
    "\n",
    "### 1.1 Short-Time Fourier Transform\n",
    "\n",
    "**Input:** Time-domain signals from 2 microphones and reference\n",
    "- $x_1(n)$: Microphone 1 signal, $n \\in [0, N-1]$\n",
    "- $x_2(n)$: Microphone 2 signal\n",
    "- $r(n)$: Reference signal (for echo cancellation)\n",
    "\n",
    "**Windowing:**\n",
    "$$w(n) = \\sin\\left(\\frac{\\pi(n + 0.5)}{L}\\right), \\quad n \\in [0, L-1]$$\n",
    "\n",
    "where $L = 320$ (20ms at 16kHz sampling rate)\n",
    "\n",
    "**STFT Computation:**\n",
    "$$X_m(k, f) = \\sum_{n=0}^{L-1} x_m(n + kH) \\cdot w(n) \\cdot e^{-j2\\pi fn/L}$$\n",
    "\n",
    "where:\n",
    "- $m \\in \\{1, 2\\}$: microphone index\n",
    "- $k$: frame index\n",
    "- $f \\in [0, 159]$: frequency bin (using only positive frequencies)\n",
    "- $H = 160$: hop size (10ms)\n",
    "\n",
    "**Magnitude and Phase:**\n",
    "$$|X_m(k, f)| = \\sqrt{\\text{Re}(X_m(k,f))^2 + \\text{Im}(X_m(k,f))^2}$$\n",
    "$$\\angle X_m(k, f) = \\arctan\\left(\\frac{\\text{Im}(X_m(k,f))}{\\text{Re}(X_m(k,f))}\\right)$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $[B, T]$ where $B$ = batch size, $T$ = time samples\n",
    "- After STFT: $[B, K, F]$ where $K$ = number of frames, $F = 161$ frequency bins\n",
    "- Network uses: $[B, K, 320]$ (concatenating real and imaginary parts)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Pre-processing Layer\n",
    "\n",
    "### 2.1 FFT Layer\n",
    "Converts time-domain to frequency-domain representation.\n",
    "\n",
    "**Input dimensions:** $[B, 1, 160]$ per microphone\n",
    "**Output dimensions:** $[B, 1, 161]$ (magnitude spectrum)\n",
    "\n",
    "For 2 microphones:\n",
    "$$\\mathbf{X}_{\\text{pre}} = [\\mathbf{X}_1; \\mathbf{X}_2] \\in \\mathbb{R}^{B \\times 2 \\times 161}$$\n",
    "\n",
    "### 2.2 Pre-processing Transformation\n",
    "$$\\mathbf{X}_{\\text{proc}} = \\text{PreProc}(\\mathbf{X}_{\\text{pre}}) \\in \\mathbb{R}^{B \\times 2 \\times 320}$$\n",
    "\n",
    "This doubles the feature dimension to 320 (likely concatenating magnitude and phase or real/imaginary components).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Rotation Layer\n",
    "\n",
    "### 3.1 Purpose\n",
    "The Rotation layer performs a **learnable linear transformation** that:\n",
    "1. Mixes spatial information from multiple microphones\n",
    "2. Projects to higher-dimensional feature space\n",
    "3. Acts as data-driven beamforming\n",
    "4. Enhances feature separability\n",
    "\n",
    "### 3.2 Mathematical Formulation\n",
    "\n",
    "**Weight Matrix:**\n",
    "$$\\mathbf{W}_{\\text{rot}} \\in \\mathbb{R}^{640 \\times 640}$$\n",
    "\n",
    "**Bias Vector:**\n",
    "$$\\mathbf{b}_{\\text{rot}} \\in \\mathbb{R}^{640}$$\n",
    "\n",
    "**Forward Pass:**\n",
    "$$\\mathbf{Y}_{\\text{rot}} = \\mathbf{W}_{\\text{rot}} \\cdot \\mathbf{X}_{\\text{concat}} + \\mathbf{b}_{\\text{rot}}$$\n",
    "\n",
    "where $\\mathbf{X}_{\\text{concat}} \\in \\mathbb{R}^{B \\times 640}$ is the concatenated input from 2 mics (each 320-dim).\n",
    "\n",
    "**Dimension Transformation:**\n",
    "$$[B, 2, 320] \\xrightarrow{\\text{reshape}} [B, 640] \\xrightarrow{\\text{Linear}} [B, 640] \\xrightarrow{\\text{reshape}} [B, 8, 640]$$\n",
    "\n",
    "Wait, let me recalculate based on the architecture diagram...\n",
    "\n",
    "**Corrected Dimensions (from diagram):**\n",
    "- Input: 2 microphones × 320 features = $[B, 2 \\times 320]$\n",
    "- Output: 8 channels × 640 features = $[B, 8, 640]$\n",
    "\n",
    "Actually, the rotation layer output is $8 \\times 640$, so:\n",
    "\n",
    "$$\\mathbf{Y}_{\\text{rot}} \\in \\mathbb{R}^{B \\times 8 \\times 640}$$\n",
    "\n",
    "The transformation can be viewed as:\n",
    "$$\\mathbf{Y}_{\\text{rot}}[b, c, :] = \\mathbf{W}_{\\text{rot}}^{(c)} \\cdot \\mathbf{X}_{\\text{flat}}[b, :] + \\mathbf{b}_{\\text{rot}}^{(c)}$$\n",
    "\n",
    "where:\n",
    "- $c \\in [0, 7]$: output channel index\n",
    "- $\\mathbf{W}_{\\text{rot}}^{(c)} \\in \\mathbb{R}^{640 \\times 640}$\n",
    "- $\\mathbf{X}_{\\text{flat}}[b, :] \\in \\mathbb{R}^{640}$ (flattened 2×320 input)\n",
    "\n",
    "### 3.3 Why Rotation Helps\n",
    "\n",
    "**Spatial Feature Mixing:**\n",
    "$$\\mathbf{Y}_{\\text{rot}}[i] = \\sum_{j=1}^{640} w_{ij} \\cdot \\mathbf{X}[j]$$\n",
    "\n",
    "This creates **linear combinations** of features from both microphones, similar to:\n",
    "- **Beamforming:** $y = \\sum_m w_m \\cdot x_m$ (weighted sum of mic signals)\n",
    "- **ICA/PCA:** Finding optimal projections for source separation\n",
    "\n",
    "**Learned vs Traditional Beamforming:**\n",
    "- Traditional: $\\mathbf{w}$ computed from geometry/statistics\n",
    "- SGN Rotation: $\\mathbf{W}_{\\text{rot}}$ learned from data to maximize noise suppression\n",
    "\n",
    "### 3.4 Gradient Flow (Backpropagation)\n",
    "\n",
    "**Loss gradient w.r.t. output:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}} \\in \\mathbb{R}^{B \\times 8 \\times 640}$$\n",
    "\n",
    "**Gradient w.r.t. weights:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_{\\text{rot}}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}} \\cdot \\mathbf{X}_{\\text{flat}}^T$$\n",
    "\n",
    "**Gradient w.r.t. input:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{X}_{\\text{flat}}} = \\mathbf{W}_{\\text{rot}}^T \\cdot \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{Y}_{\\text{rot}}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Concatenation with Delayed Reference\n",
    "\n",
    "### 4.1 Delay Operation\n",
    "\n",
    "**Reference Signal STFT:**\n",
    "$$\\mathbf{R}(k, f) = \\text{STFT}(r(n))$$\n",
    "\n",
    "**Delayed Reference (2 frames = 20ms lookback):**\n",
    "$$\\mathbf{R}_{\\text{delayed}}(k) = [\\mathbf{R}(k-2), \\mathbf{R}(k-1)]$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Current rotated features: $[B, 8, 640]$\n",
    "- Delayed reference: $[B, 8, 960]$ (includes 2 past frames)\n",
    "\n",
    "### 4.2 Concatenation\n",
    "\n",
    "$$\\mathbf{Z} = [\\mathbf{Y}_{\\text{rot}}; \\mathbf{R}_{\\text{delayed}}] \\in \\mathbb{R}^{B \\times 8 \\times 1280}$$\n",
    "\n",
    "**Why Concatenation Helps:**\n",
    "- Provides **echo path information** for cancellation\n",
    "- Temporal alignment accounts for acoustic delay\n",
    "- Enables prediction of echo component: $\\hat{e}(k) = f(\\mathbf{R}(k-2), \\mathbf{R}(k-1))$\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Bidirectional LSTM (BiLSTM)\n",
    "\n",
    "### 5.1 LSTM Cell Equations\n",
    "\n",
    "**Forward LSTM at time $t$:**\n",
    "\n",
    "**Forget Gate:**\n",
    "$$\\mathbf{f}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_f^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_f^{(\\rightarrow)})$$\n",
    "\n",
    "**Input Gate:**\n",
    "$$\\mathbf{i}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_i^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_i^{(\\rightarrow)})$$\n",
    "\n",
    "**Cell Candidate:**\n",
    "$$\\tilde{\\mathbf{c}}_t^{(\\rightarrow)} = \\tanh(\\mathbf{W}_c^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_c^{(\\rightarrow)})$$\n",
    "\n",
    "**Cell State Update:**\n",
    "$$\\mathbf{c}_t^{(\\rightarrow)} = \\mathbf{f}_t^{(\\rightarrow)} \\odot \\mathbf{c}_{t-1}^{(\\rightarrow)} + \\mathbf{i}_t^{(\\rightarrow)} \\odot \\tilde{\\mathbf{c}}_t^{(\\rightarrow)}$$\n",
    "\n",
    "**Output Gate:**\n",
    "$$\\mathbf{o}_t^{(\\rightarrow)} = \\sigma(\\mathbf{W}_o^{(\\rightarrow)} \\cdot [\\mathbf{h}_{t-1}^{(\\rightarrow)}; \\mathbf{z}_t] + \\mathbf{b}_o^{(\\rightarrow)})$$\n",
    "\n",
    "**Hidden State:**\n",
    "$$\\mathbf{h}_t^{(\\rightarrow)} = \\mathbf{o}_t^{(\\rightarrow)} \\odot \\tanh(\\mathbf{c}_t^{(\\rightarrow)})$$\n",
    "\n",
    "**Backward LSTM** (processes sequence in reverse):\n",
    "$$\\mathbf{h}_t^{(\\leftarrow)} = \\text{LSTM}^{(\\leftarrow)}(\\mathbf{z}_t, \\mathbf{h}_{t+1}^{(\\leftarrow)})$$\n",
    "\n",
    "### 5.2 BiLSTM Output\n",
    "\n",
    "**Concatenation of forward and backward:**\n",
    "$$\\mathbf{h}_t^{\\text{bi}} = [\\mathbf{h}_t^{(\\rightarrow)}; \\mathbf{h}_t^{(\\leftarrow)}]$$\n",
    "\n",
    "**Dimension Transformation:**\n",
    "- Input: $\\mathbf{z}_t \\in \\mathbb{R}^{8 \\times 1280}$\n",
    "- Forward hidden: $\\mathbf{h}_t^{(\\rightarrow)} \\in \\mathbb{R}^{8 \\times 160}$\n",
    "- Backward hidden: $\\mathbf{h}_t^{(\\leftarrow)} \\in \\mathbb{R}^{8 \\times 160}$\n",
    "- BiLSTM output: $\\mathbf{h}_t^{\\text{bi}} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 5.3 Why BiLSTM Helps\n",
    "\n",
    "**Temporal Context:**\n",
    "- Forward LSTM: Captures past context $\\mathbf{h}_t^{(\\rightarrow)} = f(\\mathbf{z}_1, ..., \\mathbf{z}_t)$\n",
    "- Backward LSTM: Captures future context $\\mathbf{h}_t^{(\\leftarrow)} = f(\\mathbf{z}_T, ..., \\mathbf{z}_t)$\n",
    "- Combined: Full temporal context $\\mathbf{h}_t^{\\text{bi}} = f(\\mathbf{z}_1, ..., \\mathbf{z}_T)$\n",
    "\n",
    "**Benefits for Noise Suppression:**\n",
    "1. **Non-stationary noise tracking:** Adapts to time-varying noise\n",
    "2. **Speech continuity:** Uses future frames to better estimate current frame\n",
    "3. **Echo path modeling:** Tracks time-varying acoustic paths\n",
    "\n",
    "---\n",
    "\n",
    "## 6. LSTM Branches (×2)\n",
    "\n",
    "### 6.1 Dual Branch Architecture\n",
    "\n",
    "**Branch 1 (likely for Echo Cancellation):**\n",
    "$$\\mathbf{h}_t^{(1)} = \\text{LSTM}_1(\\mathbf{h}_t^{\\text{bi}}, \\mathbf{h}_{t-1}^{(1)})$$\n",
    "\n",
    "**Branch 2 (likely for Noise Suppression):**\n",
    "$$\\mathbf{h}_t^{(2)} = \\text{LSTM}_2(\\mathbf{h}_t^{\\text{bi}}, \\mathbf{h}_{t-1}^{(2)})$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input to each branch: $\\mathbf{h}_t^{\\text{bi}} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Output from each branch: $\\mathbf{h}_t^{(i)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 6.2 LSTM Cell (Standard)\n",
    "\n",
    "Each branch uses standard LSTM equations (same as BiLSTM but unidirectional):\n",
    "\n",
    "$$\\mathbf{f}_t = \\sigma(\\mathbf{W}_f \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_f)$$\n",
    "$$\\mathbf{i}_t = \\sigma(\\mathbf{W}_i \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_i)$$\n",
    "$$\\tilde{\\mathbf{c}}_t = \\tanh(\\mathbf{W}_c \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_c)$$\n",
    "$$\\mathbf{c}_t = \\mathbf{f}_t \\odot \\mathbf{c}_{t-1} + \\mathbf{i}_t \\odot \\tilde{\\mathbf{c}}_t$$\n",
    "$$\\mathbf{o}_t = \\sigma(\\mathbf{W}_o \\cdot [\\mathbf{h}_{t-1}; \\mathbf{x}_t] + \\mathbf{b}_o)$$\n",
    "$$\\mathbf{h}_t = \\mathbf{o}_t \\odot \\tanh(\\mathbf{c}_t)$$\n",
    "\n",
    "### 6.3 Why Dual Branches Help\n",
    "\n",
    "**Task Decomposition:**\n",
    "- **Branch 1 specialization:** Learns echo-specific patterns\n",
    "  - Echo is correlated with reference signal\n",
    "  - Requires modeling linear/non-linear echo paths\n",
    "  \n",
    "- **Branch 2 specialization:** Learns noise-specific patterns\n",
    "  - Noise is uncorrelated with reference\n",
    "  - Requires statistical noise modeling\n",
    "\n",
    "**Mathematical Intuition:**\n",
    "$$\\mathbf{y}_{\\text{noisy}} = \\mathbf{s}_{\\text{clean}} + \\mathbf{e}_{\\text{echo}} + \\mathbf{n}_{\\text{noise}}$$\n",
    "\n",
    "- Branch 1 estimates: $\\hat{\\mathbf{e}}_{\\text{echo}}$\n",
    "- Branch 2 estimates: $\\hat{\\mathbf{n}}_{\\text{noise}}$\n",
    "- Combined: $\\hat{\\mathbf{s}}_{\\text{clean}} = \\mathbf{y}_{\\text{noisy}} - \\hat{\\mathbf{e}}_{\\text{echo}} - \\hat{\\mathbf{n}}_{\\text{noise}}$\n",
    "\n",
    "**Multi-task Learning Benefit:**\n",
    "- Shared BiLSTM learns common representations\n",
    "- Separate branches learn task-specific features\n",
    "- Prevents interference between EC and NS objectives\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Fully Connected (FC) Layers\n",
    "\n",
    "### 7.1 FC Layer 1 (after Branch 1)\n",
    "\n",
    "**Linear Transformation:**\n",
    "$$\\mathbf{y}_1 = \\mathbf{W}_1 \\cdot \\mathbf{h}^{(1)} + \\mathbf{b}_1$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $\\mathbf{h}^{(1)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Weights: $\\mathbf{W}_1 \\in \\mathbb{R}^{640 \\times 320}$\n",
    "- Output: $\\mathbf{y}_1 \\in \\mathbb{R}^{8 \\times 640}$\n",
    "\n",
    "**Activation (typically ReLU or none):**\n",
    "$$\\mathbf{y}_1 = \\max(0, \\mathbf{W}_1 \\cdot \\mathbf{h}^{(1)} + \\mathbf{b}_1)$$\n",
    "\n",
    "### 7.2 FC Layer 2 (after Branch 2)\n",
    "\n",
    "**Linear Transformation:**\n",
    "$$\\mathbf{y}_2 = \\mathbf{W}_2 \\cdot \\mathbf{h}^{(2)} + \\mathbf{b}_2$$\n",
    "\n",
    "**Dimensions:**\n",
    "- Input: $\\mathbf{h}^{(2)} \\in \\mathbb{R}^{8 \\times 320}$\n",
    "- Weights: $\\mathbf{W}_2 \\in \\mathbb{R}^{320 \\times 320}$\n",
    "- Output: $\\mathbf{y}_2 \\in \\mathbb{R}^{8 \\times 320}$\n",
    "\n",
    "### 7.3 Why FC Layers Help\n",
    "\n",
    "**Non-linear Mapping:**\n",
    "- Maps LSTM features to mask/gain space\n",
    "- Learns complex relationships: $\\text{Mask} = f_{\\text{FC}}(\\text{LSTM features})$\n",
    "\n",
    "**Dimension Matching:**\n",
    "- Ensures outputs match for combination\n",
    "- FC1 expands: $320 \\rightarrow 640$ (more capacity)\n",
    "- FC2 maintains: $320 \\rightarrow 320$ (refinement)\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Filter Block (Mask Generation)\n",
    "\n",
    "### 8.1 Feature Combination\n",
    "\n",
    "**Concatenation or Addition:**\n",
    "$$\\mathbf{y}_{\\text{combined}} = [\\mathbf{y}_1; \\mathbf{y}_2] \\quad \\text{or} \\quad \\mathbf{y}_{\\text{combined}} = \\mathbf{y}_1 + \\mathbf{y}_2$$\n",
    "\n",
    "Based on diagram (⊕ symbol), likely addition after dimension matching:\n",
    "$$\\mathbf{y}_{\\text{combined}} = \\mathbf{y}_1[:, :320] + \\mathbf{y}_2 \\in \\mathbb{R}^{8 \\times 320}$$\n",
    "\n",
    "### 8.2 Mask Computation\n",
    "\n",
    "**Final FC Layer:**\n",
    "$$\\mathbf{m}_{\\text{logits}} = \\mathbf{W}_{\\text{mask}} \\cdot \\mathbf{y}_{\\text{combined}} + \\mathbf{b}_{\\text{mask}}$$\n",
    "\n",
    "**Sigmoid Activation (for gain mask):**\n",
    "$$\\mathbf{M}(k, f) = \\sigma(\\mathbf{m}_{\\text{logits}}(k, f)) = \\frac{1}{1 + e^{-\\mathbf{m}_{\\text{logits}}(k, f)}}$$\n",
    "\n",
    "where $\\mathbf{M}(k, f) \\in [0, 1]$ is the gain mask for frame $k$, frequency $f$.\n",
    "\n",
    "**Alternative: Softmax (for ratio mask):**\n",
    "$$\\mathbf{M}_{\\text{speech}}(k, f) = \\frac{e^{\\mathbf{m}_{\\text{speech}}(k, f)}}{e^{\\mathbf{m}_{\\text{speech}}(k, f)} + e^{\\mathbf{m}_{\\text{noise}}(k, f)}}$$\n",
    "\n",
    "### 8.3 Adaptive Filtering\n",
    "\n",
    "**Apply Mask to Noisy Spectrum:**\n",
    "$$\\hat{\\mathbf{S}}_{\\text{clean}}(k, f) = \\mathbf{M}(k, f) \\cdot \\mathbf{X}_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**Element-wise multiplication:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = M(k, f) \\times X_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**In complex domain:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = M(k, f) \\times |X_{\\text{noisy}}(k, f)| \\times e^{j\\angle X_{\\text{noisy}}(k, f)}$$\n",
    "\n",
    "### 8.4 Why Adaptive Filtering Works\n",
    "\n",
    "**Frequency-Selective Suppression:**\n",
    "- Each frequency bin has independent gain $M(k, f)$\n",
    "- Suppresses noise-dominated bins: $M(k, f) \\approx 0$\n",
    "- Preserves speech-dominated bins: $M(k, f) \\approx 1$\n",
    "\n",
    "**Comparison to Wiener Filter:**\n",
    "\n",
    "Traditional Wiener filter:\n",
    "$$M_{\\text{Wiener}}(k, f) = \\frac{|S(k, f)|^2}{|S(k, f)|^2 + |N(k, f)|^2}$$\n",
    "\n",
    "SGN learned mask:\n",
    "$$M_{\\text{SGN}}(k, f) = \\sigma(\\text{NN}(\\mathbf{X}_{\\text{noisy}}, \\mathbf{R}_{\\text{ref}}))$$\n",
    "\n",
    "**Advantages of learned mask:**\n",
    "1. Non-linear: Can model complex noise patterns\n",
    "2. Context-aware: Uses temporal context from LSTM\n",
    "3. Multi-microphone: Leverages spatial information\n",
    "4. Adaptive: Learns from data, not assumptions\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Inverse STFT (Post-processing)\n",
    "\n",
    "### 9.1 Inverse FFT\n",
    "\n",
    "**Reconstruct Complex Spectrum:**\n",
    "$$\\hat{S}_{\\text{clean}}(k, f) = |\\hat{S}_{\\text{clean}}(k, f)| \\times e^{j\\angle X_{\\text{noisy}}(k, f)}$$\n",
    "\n",
    "(Phase is typically preserved from noisy signal)\n",
    "\n",
    "**Inverse FFT:**\n",
    "$$\\hat{s}_{\\text{clean}}(n + kH) = \\text{IFFT}(\\hat{S}_{\\text{clean}}(k, :))$$\n",
    "\n",
    "### 9.2 Overlap-Add\n",
    "\n",
    "**Windowing:**\n",
    "$$\\hat{s}_{\\text{windowed}}(n + kH) = \\hat{s}_{\\text{clean}}(n + kH) \\times w(n)$$\n",
    "\n",
    "**Overlap-Add Reconstruction:**\n",
    "$$\\hat{s}_{\\text{output}}(n) = \\sum_{k} \\hat{s}_{\\text{windowed}}(n - kH)$$\n",
    "\n",
    "**Normalization (for 50% overlap):**\n",
    "$$\\hat{s}_{\\text{output}}(n) = \\frac{\\sum_{k} \\hat{s}_{\\text{windowed}}(n - kH)}{\\sum_{k} w^2(n - kH)}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Loss Function\n",
    "\n",
    "### 10.1 Time-Domain Loss (MSE)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{time}} = \\frac{1}{N} \\sum_{n=1}^{N} (\\hat{s}_{\\text{clean}}(n) - s_{\\text{target}}(n))^2$$\n",
    "\n",
    "### 10.2 Frequency-Domain Loss (MSE on Magnitude)\n",
    "\n",
    "$$\\mathcal{L}_{\\text{freq}} = \\frac{1}{KF} \\sum_{k=1}^{K} \\sum_{f=1}^{F} (|\\hat{S}_{\\text{clean}}(k, f)| - |S_{\\text{target}}(k, f)|)^2$$\n",
    "\n",
    "### 10.3 Perceptual Loss (SI-SNR)\n",
    "\n",
    "**Scale-Invariant SNR:**\n",
    "$$\\text{SI-SNR} = 10 \\log_{10} \\frac{\\|\\alpha s_{\\text{target}}\\|^2}{\\|\\alpha s_{\\text{target}} - \\hat{s}_{\\text{clean}}\\|^2}$$\n",
    "\n",
    "where $\\alpha = \\frac{\\langle \\hat{s}_{\\text{clean}}, s_{\\text{target}} \\rangle}{\\|s_{\\text{target}}\\|^2}$\n",
    "\n",
    "**Loss:**\n",
    "$$\\mathcal{L}_{\\text{SI-SNR}} = -\\text{SI-SNR}$$\n",
    "\n",
    "### 10.4 Combined Loss\n",
    "\n",
    "$$\\mathcal{L}_{\\text{total}} = \\lambda_1 \\mathcal{L}_{\\text{time}} + \\lambda_2 \\mathcal{L}_{\\text{freq}} + \\lambda_3 \\mathcal{L}_{\\text{SI-SNR}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Backpropagation Through Time (BPTT)\n",
    "\n",
    "### 11.1 Gradient Flow\n",
    "\n",
    "**Loss gradient w.r.t. mask:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{M}(k, f)} = \\frac{\\partial \\mathcal{L}}{\\partial \\hat{S}(k, f)} \\cdot X_{\\text{noisy}}(k, f)$$\n",
    "\n",
    "**Gradient through sigmoid:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{m}_{\\text{logits}}} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{M}} \\cdot \\mathbf{M} \\cdot (1 - \\mathbf{M})$$\n",
    "\n",
    "**Gradient through FC layers:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_i} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}_i} \\cdot \\mathbf{h}^{(i)T}$$\n",
    "\n",
    "### 11.2 LSTM Gradient\n",
    "\n",
    "**Gradient through LSTM cell:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{y}_t} + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_{t+1}} \\cdot \\frac{\\partial \\mathbf{h}_{t+1}}{\\partial \\mathbf{h}_t}$$\n",
    "\n",
    "**Cell state gradient:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{h}_t} \\cdot \\mathbf{o}_t \\cdot (1 - \\tanh^2(\\mathbf{c}_t)) + \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_{t+1}} \\cdot \\mathbf{f}_{t+1}$$\n",
    "\n",
    "**Gate gradients:**\n",
    "$$\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{f}_t} = \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{c}_t} \\cdot \\mathbf{c}_{t-1} \\cdot \\mathbf{f}_t \\cdot (1 - \\mathbf{f}_t)$$\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Parameter Count Analysis\n",
    "\n",
    "### 12.1 Layer-wise Parameters\n",
    "\n",
    "**Rotation Layer:**\n",
    "- Weights: $640 \\times 640 = 409,600$\n",
    "- Bias: $640$\n",
    "- Total: **409,640**\n",
    "\n",
    "**BiLSTM:**\n",
    "- Forward LSTM: $4 \\times (320 \\times (1280 + 160) + 160) = 4 \\times 461,600 = 1,846,400$\n",
    "- Backward LSTM: $1,846,400$\n",
    "- Total: **3,692,800**\n",
    "\n",
    "**LSTM Branch 1:**\n",
    "- Parameters: $4 \\times (320 \\times (320 + 320) + 320) = 4 \\times 205,120 = 820,480$\n",
    "- Total: **820,480**\n",
    "\n",
    "**LSTM Branch 2:**\n",
    "- Parameters: **820,480**\n",
    "\n",
    "**FC Layers:**\n",
    "- FC1: $640 \\times 320 + 640 = 205,440$\n",
    "- FC2: $320 \\times 320 + 320 = 102,720$\n",
    "- Total: **308,160**\n",
    "\n",
    "**Total Parameters:**\n",
    "$$409,640 + 3,692,800 + 820,480 + 820,480 + 308,160 = 6,051,560 \\approx 6M$$\n",
    "\n",
    "(Close to stated 5.5M, difference may be in exact architecture details)\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Computational Complexity\n",
    "\n",
    "### 13.1 FLOPs per Frame\n",
    "\n",
    "**STFT/ISTFT:**\n",
    "- FFT: $O(F \\log F) = O(320 \\log 320) \\approx 2,560$ FLOPs\n",
    "\n",
    "**Rotation Layer:**\n",
    "- Matrix multiply: $640 \\times 640 = 409,600$ FLOPs\n",
    "\n",
    "**BiLSTM:**\n",
    "- Forward: $4 \\times 320 \\times 1440 = 1,843,200$ FLOPs\n",
    "- Backward: $1,843,200$ FLOPs\n",
    "- Total: $3,686,400$ FLOPs\n",
    "\n",
    "**LSTM Branches:**\n",
    "- Branch 1: $4 \\times 320 \\times 640 = 819,200$ FLOPs\n",
    "- Branch 2: $819,200$ FLOPs\n",
    "- Total: $1,638,400$ FLOPs\n",
    "\n",
    "**FC Layers:**\n",
    "- FC1: $640 \\times 320 = 204,800$ FLOPs\n",
    "- FC2: $320 \\times 320 = 102,400$ FLOPs\n",
    "- Total: $307,200$ FLOPs\n",
    "\n",
    "**Total per frame:**\n",
    "$$2,560 + 409,600 + 3,686,400 + 1,638,400 + 307,200 = 6,044,160 \\approx 6M \\text{ FLOPs}$$\n",
    "\n",
    "**At 100 fps (10ms hop):**\n",
    "$$6M \\times 100 = 600M \\text{ FLOPs/s} = 0.6 \\text{ GFLOPS} \\approx 0.5 \\text{ GMAC/s}$$\n",
    "\n",
    "(Matches stated complexity)\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Summary of Dimension Flow\n",
    "\n",
    "```\n",
    "Input Audio (2 mics + ref):\n",
    "  [B, T] × 3\n",
    "\n",
    "↓ STFT\n",
    "\n",
    "Spectrograms:\n",
    "  [B, K, 161] × 3\n",
    "\n",
    "↓ Pre-processing\n",
    "\n",
    "Features:\n",
    "  [B, K, 2, 320]\n",
    "\n",
    "↓ Rotation Layer\n",
    "\n",
    "Rotated Features:\n",
    "  [B, K, 8, 640]\n",
    "\n",
    "↓ Concat with Delayed Ref\n",
    "\n",
    "Combined:\n",
    "  [B, K, 8, 1280]\n",
    "\n",
    "↓ BiLSTM\n",
    "\n",
    "Temporal Features:\n",
    "  [B, K, 8, 320]\n",
    "\n",
    "↓ Dual LSTM Branches\n",
    "\n",
    "Branch 1: [B, K, 8, 320]\n",
    "Branch 2: [B, K, 8, 320]\n",
    "\n",
    "↓ FC Layers\n",
    "\n",
    "FC1 out: [B, K, 8, 640]\n",
    "FC2 out: [B, K, 8, 320]\n",
    "\n",
    "↓ Combine + Filter\n",
    "\n",
    "Mask:\n",
    "  [B, K, 161]\n",
    "\n",
    "↓ Apply Mask\n",
    "\n",
    "Clean Spectrum:\n",
    "  [B, K, 161]\n",
    "\n",
    "↓ ISTFT\n",
    "\n",
    "Output Audio:\n",
    "  [B, T]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 15. Key Takeaways\n",
    "\n",
    "1. **Rotation Layer** = Learned beamforming (spatial mixing)\n",
    "2. **BiLSTM** = Temporal context (past + future)\n",
    "3. **Dual Branches** = Task decomposition (EC + NS)\n",
    "4. **FC Layers** = Non-linear mapping to mask space\n",
    "5. **Adaptive Filtering** = Frequency-selective suppression\n",
    "\n",
    "**Why SGN Works:**\n",
    "- Combines spatial (multi-mic) and temporal (LSTM) processing\n",
    "- Learns optimal features for noise suppression\n",
    "- Adapts to non-stationary noise and echo\n",
    "- Efficient: Only 5.5M params, 0.5 GMAC/s\n",
    "\n",
    "---\n",
    "\n",
    "*End of Mathematical Formulation*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024fd364",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
