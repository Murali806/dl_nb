# Mathematical Derivation of Gradients for Three-Layer Linear Neural Network

This document provides a step-by-step mathematical derivation of the backpropagation gradients for a **three-layer purely linear neural network** (no activation functions).

---

## âœ… Problem Setup

### Network Architecture (All Linear - No Activations)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Input (x) â†’ Layer 1 â†’ Layer 2 â†’ Layer 3 â†’ Output (Å·)         â”‚
â”‚                                                                 â”‚
â”‚  x â†’ [Wâ‚Â·x + bâ‚] â†’ [Wâ‚‚Â·hâ‚ + bâ‚‚] â†’ [Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ] â†’ Å·           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Notation

**Layer 1 (Hidden Layer 1):**
- Weight: Wâ‚
- Bias: bâ‚
- Linear output: zâ‚ = Wâ‚Â·x + bâ‚
- Output: hâ‚ = zâ‚ (no activation, just pass through)

**Layer 2 (Hidden Layer 2):**
- Weight: Wâ‚‚
- Bias: bâ‚‚
- Linear output: zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
- Output: hâ‚‚ = zâ‚‚ (no activation, just pass through)

**Layer 3 (Output Layer):**
- Weight: Wâ‚ƒ
- Bias: bâ‚ƒ
- Linear output: zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
- Output: Å· = zâ‚ƒ (no activation)

---

## ğŸ¯ Forward Propagation

### Step-by-Step Computation

```
1. Layer 1:  zâ‚ = Wâ‚Â·x + bâ‚
             hâ‚ = zâ‚

2. Layer 2:  zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
             hâ‚‚ = zâ‚‚

3. Layer 3:  zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
             Å· = zâ‚ƒ
```

### Simplified View (Since hâ‚ = zâ‚ and hâ‚‚ = zâ‚‚):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  hâ‚ = Wâ‚Â·x + bâ‚                                â”‚
â”‚                                                 â”‚
â”‚  hâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚ = Wâ‚‚Â·(Wâ‚Â·x + bâ‚) + bâ‚‚        â”‚
â”‚                                                 â”‚
â”‚  Å· = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ                                â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‰ Loss Function

We use **Mean Squared Error (MSE)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   L = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)Â²    â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For a single sample:
```
L = (Å· - y)Â²
```

### Derivative of Loss with Respect to Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚Å· = 2(Å· - y)                 â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For batch training with n samples:
```
âˆ‚L/âˆ‚Å· = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)
```

## ğŸ”„ Backpropagation: The Chain Rule

The key to backpropagation is the **chain rule** from calculus:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   For f(g(x)):                     â”‚
â”‚                                     â”‚
â”‚   df/dx = (df/dg) Ã— (dg/dx)        â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

We compute gradients **layer by layer**, moving **backward** from output to input.

---

## ğŸ“ Layer 3 Gradients (Output Layer)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ƒ and âˆ‚L/âˆ‚bâ‚ƒ

**Step 1**: We already have the derivative of loss with respect to output:
```
âˆ‚L/âˆ‚Å· = 2(Å· - y)
```

**Step 2**: Since Å· = zâ‚ƒ (no activation function):
```
âˆ‚Å·/âˆ‚zâ‚ƒ = 1
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚ƒ = âˆ‚L/âˆ‚Å· Ã— âˆ‚Å·/âˆ‚zâ‚ƒ = 2(Å· - y) Ã— 1 = 2(Å· - y)
```

---

### Computing âˆ‚L/âˆ‚Wâ‚ƒ

**Step 4**: Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ, the derivative with respect to Wâ‚ƒ is:
```
âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ = hâ‚‚
```

**Why?** Treating bâ‚ƒ as a constant, the derivative of Wâ‚ƒÂ·hâ‚‚ with respect to Wâ‚ƒ is hâ‚‚.

**Step 5**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚           â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


---

### Computing âˆ‚L/âˆ‚bâ‚ƒ

**Step 6**: Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ, the derivative with respect to bâ‚ƒ is:
```
âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ = 1
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y) Ã— 1            â”‚
â”‚          = 2(Å· - y)                â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Summary for Layer 3:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚           â•‘
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:**
- Weight gradient depends on the previous layer's output (hâ‚‚)
- Bias gradient is just the error signal

---

## ğŸ“ Layer 2 Gradients (Hidden Layer 2)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚‚ and âˆ‚L/âˆ‚bâ‚‚

**Step 1**: We already have:
```
âˆ‚L/âˆ‚zâ‚ƒ = 2(Å· - y)
```

**Step 2**: We need to propagate this gradient back to hâ‚‚. Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = Wâ‚ƒ
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚hâ‚‚ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ
```

**Step 4**: Since hâ‚‚ = zâ‚‚ (no activation):
```
âˆ‚hâ‚‚/âˆ‚zâ‚‚ = 1
```

**Step 5**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚‚ = âˆ‚L/âˆ‚hâ‚‚ Ã— âˆ‚hâ‚‚/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— 1 = 2(Å· - y) Ã— Wâ‚ƒ
```

---

### Computing âˆ‚L/âˆ‚Wâ‚‚

**Step 6**: Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = hâ‚
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚Wâ‚‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— hâ‚     â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Wâ‚‚ = 2(1.116 - 4.0) Ã— 1.2 Ã— 1.1
       = -5.768 Ã— 1.2 Ã— 1.1
       = -7.614
```

---

### Computing âˆ‚L/âˆ‚bâ‚‚

**Step 8**: Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚bâ‚‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— 1      â”‚
â”‚          = 2(Å· - y) Ã— Wâ‚ƒ           â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚bâ‚‚ = 2(1.116 - 4.0) Ã— 1.2
       = -5.768 Ã— 1.2
       = -6.922
```

---

### Summary for Layer 2:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— hâ‚     â•‘
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ           â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:**
- Gradient flows backward through Wâ‚ƒ
- Weight gradient also depends on hâ‚ (previous layer output)

---

## ğŸ“ Layer 1 Gradients (Hidden Layer 1)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ and âˆ‚L/âˆ‚bâ‚

**Step 1**: We already have:
```
âˆ‚L/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ
```

**Step 2**: We need to propagate this gradient back to hâ‚. Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚hâ‚ = Wâ‚‚
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚hâ‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚hâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚
```

**Step 4**: Since hâ‚ = zâ‚ (no activation):
```
âˆ‚hâ‚/âˆ‚zâ‚ = 1
```

**Step 5**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚ = âˆ‚L/âˆ‚hâ‚ Ã— âˆ‚hâ‚/âˆ‚zâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— 1 = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚
```

---

### Computing âˆ‚L/âˆ‚Wâ‚

**Step 6**: Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚Wâ‚ = x
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚Wâ‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— x     â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Wâ‚ = 2(1.116 - 4.0) Ã— 1.2 Ã— 0.8 Ã— 2.0
       = -5.768 Ã— 1.2 Ã— 0.8 Ã— 2.0
       = -11.078
```

---

### Computing âˆ‚L/âˆ‚bâ‚

**Step 8**: Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚bâ‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚bâ‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚   âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— 1     â”‚
â”‚          = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚         â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚bâ‚ = 2(1.116 - 4.0) Ã— 1.2 Ã— 0.8
       = -5.768 Ã— 1.2 Ã— 0.8
       = -5.539
```

---

### Summary for Layer 1:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                         â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— x     â•‘
â•‘                                         â•‘
â•‘   âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚         â•‘
â•‘                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:**
- Gradient flows backward through both Wâ‚ƒ and Wâ‚‚
- Weight gradient also depends on input x
- Notice the pattern: each layer multiplies by the next layer's weight

---

## ğŸ“Š Complete Gradient Summary

For a three-layer **linear** neural network:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘  OUTPUT LAYER (Layer 3):                                 â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚                                 â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                                      â•‘
â•‘                                                           â•‘
â•‘  HIDDEN LAYER 2:                                         â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— hâ‚                           â•‘
â•‘  âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ                                â•‘
â•‘                                                           â•‘
â•‘  HIDDEN LAYER 1:                                         â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— x                       â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚                           â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Pattern Recognition:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Notice the pattern:                                    â”‚
â”‚                                                         â”‚
â”‚  â€¢ Each layer's gradient includes 2(Å· - y)             â”‚
â”‚  â€¢ Gradients accumulate weights as we go backward      â”‚
â”‚  â€¢ Weight gradients multiply by previous layer output  â”‚
â”‚  â€¢ Bias gradients don't depend on previous output     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Gradient Descent Update Rules

Once we have all gradients, we update parameters using:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   Wâ‚ƒ â† Wâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚ƒ)          â”‚
â”‚   bâ‚ƒ â† bâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚bâ‚ƒ)          â”‚
â”‚                                     â”‚
â”‚   Wâ‚‚ â† Wâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚‚)          â”‚
â”‚   bâ‚‚ â† bâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚‚)          â”‚
â”‚                                     â”‚
â”‚   Wâ‚ â† Wâ‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚)          â”‚
â”‚   bâ‚ â† bâ‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚)          â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Where Î± is the **learning rate** (e.g., 0.01).

### Numerical Example (Î± = 0.01):

Using our computed gradients:

```
Wâ‚ƒ â† 1.2 - 0.01 Ã— (-3.922) = 1.2 + 0.039 = 1.239
bâ‚ƒ â† 0.3 - 0.01 Ã— (-5.768) = 0.3 + 0.058 = 0.358

Wâ‚‚ â† 0.8 - 0.01 Ã— (-7.614) = 0.8 + 0.076 = 0.876
bâ‚‚ â† -0.2 - 0.01 Ã— (-6.922) = -0.2 + 0.069 = -0.131

Wâ‚ â† 0.5 - 0.01 Ã— (-11.078) = 0.5 + 0.111 = 0.611
bâ‚ â† 0.1 - 0.01 Ã— (-5.539) = 0.1 + 0.055 = 0.155
```

**Notice:** All parameters **increased** because all gradients were **negative**, meaning we need to move in the positive direction to reduce the loss!

---

## ğŸ“ Complete Numerical Example

Let's verify our gradients with a full forward and backward pass.

### Given:
- Input: x = 2.0
- True output: y = 4.0
- Initial parameters:
  - Wâ‚ = 0.5, bâ‚ = 0.1
  - Wâ‚‚ = 0.8, bâ‚‚ = -0.2
  - Wâ‚ƒ = 1.2, bâ‚ƒ = 0.3

### Forward Pass:

```
hâ‚ = Wâ‚Â·x + bâ‚ = 0.5 Ã— 2.0 + 0.1 = 1.1

hâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚ = 0.8 Ã— 1.1 + (-0.2) = 0.68

Å· = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ = 1.2 Ã— 0.68 + 0.3 = 1.116
```

### Loss:

```
L = (Å· - y)Â² = (1.116 - 4.0)Â² = (-2.884)Â² = 8.318
```

### Backward Pass:

```
Error signal: 2(Å· - y) = 2(1.116 - 4.0) = -5.768

Layer 3:
âˆ‚L/âˆ‚Wâ‚ƒ = -5.768 Ã— 0.68 = -3.922
âˆ‚L/âˆ‚bâ‚ƒ = -5.768

Layer 2:
âˆ‚L/âˆ‚Wâ‚‚ = -5.768 Ã— 1.2 Ã— 1.1 = -7.614
âˆ‚L/âˆ‚bâ‚‚ = -5.768 Ã— 1.2 = -6.922

Layer 1:
âˆ‚L/âˆ‚Wâ‚ = -5.768 Ã— 1.2 Ã— 0.8 Ã— 2.0 = -11.078
âˆ‚L/âˆ‚bâ‚ = -5.768 Ã— 1.2 Ã— 0.8 = -5.539
```

### Update (Î± = 0.01):

```
Wâ‚ƒ = 1.2 - 0.01(-3.922) = 1.239
bâ‚ƒ = 0.3 - 0.01(-5.768) = 0.358

Wâ‚‚ = 0.8 - 0.01(-7.614) = 0.876
bâ‚‚ = -0.2 - 0.01(-6.922) = -0.131

Wâ‚ = 0.5 - 0.01(-11.078) = 0.611
bâ‚ = 0.1 - 0.01(-5.539) = 0.155
```

### Verify: Forward Pass with Updated Parameters

```
hâ‚ = 0.611 Ã— 2.0 + 0.155 = 1.377

hâ‚‚ = 0.876 Ã— 1.377 + (-0.131) = 1.075

Å· = 1.239 Ã— 1.075 + 0.358 = 1.690
```

**New Loss:**
```
L = (1.690 - 4.0)Â² = (-2.310)Â² = 5.336
```

**Loss decreased from 8.318 to 5.336!** âœ… Gradient descent is working!

---

## ğŸ§® Batch Training

For multiple samples (batch size n), we average the gradients:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ƒ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Ã— hâ‚‚áµ¢                â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ƒ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)                       â•‘
â•‘                                                           â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚‚ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— hâ‚áµ¢           â•‘
â•‘  âˆ‚L/âˆ‚bâ‚‚ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ                  â•‘
â•‘                                                           â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— xáµ¢       â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ = (2/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— Wâ‚‚            â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ¯ Key Insights

### 1. **Linear Networks are Simple**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  No activation functions means:                         â”‚
â”‚  â€¢ No activation derivatives (no tanh', sigmoid', etc.) â”‚
â”‚  â€¢ Cleaner chain rule application                      â”‚
â”‚  â€¢ Easier to understand backpropagation               â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Gradient Flow Pattern**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Gradients flow backward by multiplying weights:        â”‚
â”‚                                                         â”‚
â”‚  Layer 3: Just the error signal                        â”‚
â”‚  Layer 2: Error Ã— Wâ‚ƒ                                   â”‚
â”‚  Layer 1: Error Ã— Wâ‚ƒ Ã— Wâ‚‚                             â”‚
â”‚                                                         â”‚
â”‚  Each layer adds one more weight to the product!       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. **Weight vs Bias Gradients**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Weight gradients: Multiply by previous layer output   â”‚
â”‚  Bias gradients: Don't depend on previous output      â”‚
â”‚                                                         â”‚
â”‚  This is because:                                      â”‚
â”‚  â€¢ âˆ‚(WÂ·h)/âˆ‚W = h                                      â”‚
â”‚  â€¢ âˆ‚(b)/âˆ‚b = 1                                        â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. **Why Linear Networks are Limited**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  A 3-layer linear network can be collapsed:            â”‚
â”‚                                                         â”‚
â”‚  Å· = Wâ‚ƒ(Wâ‚‚(Wâ‚Â·x + bâ‚) + bâ‚‚) + bâ‚ƒ                     â”‚
â”‚    = (Wâ‚ƒÂ·Wâ‚‚Â·Wâ‚)Â·x + (Wâ‚ƒÂ·Wâ‚‚Â·bâ‚ + Wâ‚ƒÂ·bâ‚‚ + bâ‚ƒ)         â”‚
â”‚    = W_effectiveÂ·x + b_effective                       â”‚
â”‚                                                         â”‚
â”‚  It's equivalent to a single linear layer!             â”‚
â”‚  Can only learn linear relationships!                  â”‚
â”‚                                                         â”‚
â”‚  This is why we need activation functions in practice! â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. **Vanishing/Exploding Gradients**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Notice how gradients multiply weights:                â”‚
â”‚                                                         â”‚
â”‚  If |Wâ‚ƒ| < 1 and |Wâ‚‚| < 1:                            â”‚
â”‚  â†’ Gradients get smaller (vanishing)                   â”‚
â”‚                                                         â”‚
â”‚  If |Wâ‚ƒ| > 1 and |Wâ‚‚| > 1:                            â”‚
â”‚  â†’ Gradients get larger (exploding)                    â”‚
â”‚                                                         â”‚
â”‚  This is why weight initialization matters!            â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Verification: Numerical Gradient Check

To verify your gradient implementation, use **numerical gradients**:

```
âˆ‚L/âˆ‚W â‰ˆ [L(W + Îµ) - L(W - Îµ)] / (2Îµ)
```

Where Îµ is a small value (e.g., 1e-7).

### Example for Wâ‚ƒ:

```python
epsilon = 1e-7

# Compute loss with Wâ‚ƒ + Îµ
W3_plus = W3 + epsilon
y_pred_plus = forward_pass(x, W1, b1, W2, b2, W3_plus, b3)
loss_plus = (y_pred_plus - y)**2

# Compute loss with Wâ‚ƒ - Îµ
W3_minus = W3 - epsilon
y_pred_minus = forward_pass(x, W1, b1, W2, b2, W3_minus, b3)
loss_minus = (y_pred_minus - y)**2

# Numerical gradient
numerical_grad = (loss_plus - loss_minus) / (2 * epsilon)

# Compare with analytical gradient
analytical_grad = 2 * (y_pred - y) * h2

# Should be very close (difference < 1e-7)
print(f"Numerical: {numerical_grad}")
print(f"Analytical: {analytical_grad}")
print(f"Difference: {abs(numerical_grad - analytical_grad)}")
```

---

## ğŸ’¡ Practical Tips

### 1. **Weight Initialization**
```
â€¢ Use small random values (e.g., uniform(-0.5, 0.5))
â€¢ Or use Xavier initialization: W ~ N(0, 1/âˆšn_in)
â€¢ Avoid initializing all weights to zero!
```

### 2. **Learning Rate Selection**
```
â€¢ Start with Î± = 0.01
â€¢ If loss oscillates: decrease Î±
â€¢ If loss decreases too slowly: increase Î±
â€¢ Consider learning rate schedules
```

### 3. **Monitoring Training**
```
â€¢ Plot loss vs iterations
â€¢ Loss should decrease monotonically
â€¢ If loss increases: learning rate too high
â€¢ If loss plateaus: might need activation functions!
```

### 4. **Debugging Gradients**
```
â€¢ Use numerical gradient checking
â€¢ Print gradient magnitudes
â€¢ Check for NaN or Inf values
â€¢ Verify gradients sum correctly for batches
```

### 5. **When to Use Linear Networks**
```
â€¢ Linear regression problems
â€¢ As a baseline model
â€¢ For understanding backpropagation
â€¢ NOT for complex non-linear problems!
```

---

## ğŸ“ Summary

### The Complete Backpropagation Algorithm:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  1. FORWARD PASS:                                      â”‚
â”‚     â€¢ Compute hâ‚ = Wâ‚Â·x + bâ‚                          â”‚
â”‚     â€¢ Compute hâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚                         â”‚
â”‚     â€¢ Compute Å· = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ                          â”‚
â”‚                                                         â”‚
â”‚  2. COMPUTE LOSS:                                      â”‚
â”‚     â€¢ L = (Å· - y)Â²                                    â”‚
â”‚                                                         â”‚
â”‚  3. BACKWARD PASS (Compute Gradients):                  |
|     Generalized = âˆ‚L/âˆ‚Wn = 2 * error * Wn+1 * hn-1      |
|                   âˆ‚L/âˆ‚Wn = 2 * error * Wn+1             |
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚                        â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                              â”‚
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— hâ‚                   â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ                         â”‚
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— x               â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚                   â”‚
â”‚                                                        â”‚
â”‚  4. UPDATE PARAMETERS:                                 â”‚
â”‚     â€¢ Wâ‚ƒ â† Wâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚ƒ)                         â”‚
â”‚     â€¢ bâ‚ƒ â† bâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚bâ‚ƒ)                         â”‚
â”‚     â€¢ Wâ‚‚ â† Wâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚‚)                         â”‚
â”‚     â€¢ bâ‚‚ â† bâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚‚)                         â”‚
â”‚     â€¢ Wâ‚ â† Wâ‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚)                         â”‚
â”‚     â€¢ bâ‚ â† bâ‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚)                         â”‚
â”‚                                                         â”‚
â”‚  5. REPEAT until convergence                           â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— Connection to Code

In Python/NumPy, the backward pass would look like:

```python
def backward(x, y, y_pred, h1, h2, W3, W2, learning_rate=0.01):
    """
    Compute gradients and update parameters for 3-layer linear network.
    """
    n = len(x)  # batch size
    
    # Error signal
    error = y_pred - y
    
    # Layer 3 gradients
    dW3 = (2.0 / n) * np.sum(error * h2)
    db3 = (2.0 / n) * np.sum(error)
    
    # Layer 2 gradients
    dW2 = (2.0 / n) * np.sum(error * W3 * h1)
    db2 = (2.0 / n) * np.sum(error * W3)
    
    # Layer 1 gradients
    dW1 = (2.0 / n) * np.sum(error * W3 * W2 * x)
    db1 = (2.0 / n) * np.sum(error * W3 * W2)
    
    # Update parameters
    W3 -= learning_rate * dW3
    b3 -= learning_rate * db3
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    
    return W3, b3, W2, b2, W1, b1
```

---

**This is how backpropagation works in a three-layer linear neural network!** ğŸ‰

The same principles extend to:
- Networks with more layers (just keep multiplying weights backward)
- Networks with activation functions (add activation derivatives)
- Different loss functions (change âˆ‚L/âˆ‚Å·)
- Different architectures (CNNs, RNNs, etc.)

**Understanding this linear case is the foundation for understanding all of deep learning!** ğŸš€
