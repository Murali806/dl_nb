# Mathematical Derivation of Gradients for Single Perceptron

This document provides a step-by-step mathematical derivation of the backpropagation gradients used in our single perceptron implementation.

---

## âœ… Problem Setup

### Model (Forward Propagation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚         Å·áµ¢ = WÂ·xáµ¢ + B              â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**where:**
- `xáµ¢` = input feature for sample i (house size)
- `W` = weight (parameter to learn)
- `B` = bias (parameter to learn)
- `Å·áµ¢` = predicted output for sample i (house price)

---

### Loss Function (Mean Squared Error)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚      L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)Â²   â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**where:**
- `yáµ¢` = true label for sample i
- `Å·áµ¢` = predicted label for sample i
- `n` = number of training samples

---

## ğŸ¯ Goal: Find âˆ‚L/âˆ‚W and âˆ‚L/âˆ‚B

We need to find how the loss changes with respect to our parameters (W and B) so we can update them using gradient descent.

---

## ğŸ” Derivation 1: Gradient with respect to Weight (âˆ‚L/âˆ‚W)

### Step 1: Write the Full Loss Function

```
L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)Â²
```

### Step 2: Substitute Forward Propagation

Since `Å·áµ¢ = WÂ·xáµ¢ + B`, we can write:

```
L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ (WÂ·xáµ¢ + B - yáµ¢)Â²
```

### Step 3: Define Error Term

**Define:**

```
Aáµ¢ = Å·áµ¢ - yáµ¢ = WÂ·xáµ¢ + B - yáµ¢
```

**So:**

```
L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ Aáµ¢Â²
```

---

### ğŸ”¬ Step-by-Step Derivative

#### 1. Derivative of L with respect to Aáµ¢

```
âˆ‚L/âˆ‚Aáµ¢ = 2/n Â· Aáµ¢
```

**Why?** Using the power rule: d/dx(xÂ²) = 2x, and the 1/n factor stays constant.

---

#### 2. Derivative of Aáµ¢ with respect to W

```
Aáµ¢ = WÂ·xáµ¢ + B - yáµ¢
```

```
âˆ‚Aáµ¢/âˆ‚W = xáµ¢
```

**Why?** The derivative of `WÂ·xáµ¢` with respect to W is `xáµ¢` (treating xáµ¢ as constant), and derivatives of B and yáµ¢ with respect to W are 0.

---

#### 3. Apply Chain Rule for Each Sample

```
âˆ‚L/âˆ‚W = Î£áµ¢â‚Œâ‚â¿ (âˆ‚L/âˆ‚Aáµ¢ Â· âˆ‚Aáµ¢/âˆ‚W)
```

**Substitute:**

```
âˆ‚L/âˆ‚W = Î£áµ¢â‚Œâ‚â¿ (2/n Â· Aáµ¢ Â· xáµ¢)
```

**Replace Aáµ¢:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚   âˆ‚L/âˆ‚W = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (WÂ·xáµ¢ + B - yáµ¢) Â· xáµ¢   â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Or equivalently:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚L/âˆ‚W = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Â· xáµ¢      â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Final Gradient for Weight

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                             â•‘
â•‘   âˆ‚L/âˆ‚W = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Â· xáµ¢      â•‘
â•‘                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:** "How much does changing the weight affect the loss, weighted by the input values?"

**In code notation:**
```python
âˆ‚Loss/âˆ‚weight = (2/n) Ã— Î£(y_pred - y_true) Ã— input
```

---

## ğŸ” Derivation 2: Gradient with respect to Bias (âˆ‚L/âˆ‚B)

### Step 1: Start with the Same Loss Function

```
L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)Â²
  = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ (WÂ·xáµ¢ + B - yáµ¢)Â²
```

### Step 2: Use the Same Error Term

**Define:**

```
Aáµ¢ = WÂ·xáµ¢ + B - yáµ¢
```

**So:**

```
L = 1/n Ã— Î£áµ¢â‚Œâ‚â¿ Aáµ¢Â²
```

---

### ğŸ”¬ Step-by-Step Derivative

#### 1. Derivative of L with respect to Aáµ¢ (same as before)

```
âˆ‚L/âˆ‚Aáµ¢ = 2/n Â· Aáµ¢
```

---

#### 2. Derivative of Aáµ¢ with respect to B

```
Aáµ¢ = WÂ·xáµ¢ + B - yáµ¢
```

```
âˆ‚Aáµ¢/âˆ‚B = 1
```

**Why?** The derivative of `WÂ·xáµ¢` with respect to B is 0 (doesn't contain B), the derivative of B with respect to B is 1, and the derivative of yáµ¢ with respect to B is 0.

---

#### 3. Apply Chain Rule for Each Sample

```
âˆ‚L/âˆ‚B = Î£áµ¢â‚Œâ‚â¿ (âˆ‚L/âˆ‚Aáµ¢ Â· âˆ‚Aáµ¢/âˆ‚B)
```

**Substitute:**

```
âˆ‚L/âˆ‚B = Î£áµ¢â‚Œâ‚â¿ (2/n Â· Aáµ¢ Â· 1)
```

**Replace Aáµ¢:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚   âˆ‚L/âˆ‚B = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (WÂ·xáµ¢ + B - yáµ¢) â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Or equivalently:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚B = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)    â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ Final Gradient for Bias

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚B = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)    â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:** "How much does changing the bias affect the loss, averaged across all samples?"

**In code notation:**
```python
âˆ‚Loss/âˆ‚bias = (2/n) Ã— Î£(y_pred - y_true)
```

---

## ğŸ”„ Gradient Descent Update Rules

Once we have the gradients, we update the parameters:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   W_new = W_old - Î± Ã— (âˆ‚L/âˆ‚W)      â”‚
â”‚                                     â”‚
â”‚   B_new = B_old - Î± Ã— (âˆ‚L/âˆ‚B)      â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**where:**
- `Î±` = learning rate (e.g., 0.01)
- We move in the **opposite direction** of the gradient to minimize loss

---

## ğŸ“ Concrete Numerical Example

Let's work through a complete example with 3 data points to see the gradients in action.

### Given Data:

```
Sample 1: xâ‚ = 2, yâ‚ = 5
Sample 2: xâ‚‚ = 3, yâ‚‚ = 7
Sample 3: xâ‚ƒ = 4, yâ‚ƒ = 9
```

### Current Parameters:

```
W = 1.5
B = 1.0
```

---

### Step 1: Forward Propagation

```
Å·â‚ = WÂ·xâ‚ + B = 1.5 Ã— 2 + 1.0 = 4.0
Å·â‚‚ = WÂ·xâ‚‚ + B = 1.5 Ã— 3 + 1.0 = 5.5
Å·â‚ƒ = WÂ·xâ‚ƒ + B = 1.5 Ã— 4 + 1.0 = 7.0
```

---

### Step 2: Compute Errors

```
Aâ‚ = Å·â‚ - yâ‚ = 4.0 - 5.0 = -1.0
Aâ‚‚ = Å·â‚‚ - yâ‚‚ = 5.5 - 7.0 = -1.5
Aâ‚ƒ = Å·â‚ƒ - yâ‚ƒ = 7.0 - 9.0 = -2.0
```

---

### Step 3: Compute Loss

```
L = 1/3 Ã— [(âˆ’1.0)Â² + (âˆ’1.5)Â² + (âˆ’2.0)Â²]
  = 1/3 Ã— [1.0 + 2.25 + 4.0]
  = 1/3 Ã— 7.25
  = 2.417
```

---

### Step 4: Compute Weight Gradient

```
âˆ‚L/âˆ‚W = 2/3 Ã— [Aâ‚Â·xâ‚ + Aâ‚‚Â·xâ‚‚ + Aâ‚ƒÂ·xâ‚ƒ]
      = 2/3 Ã— [(âˆ’1.0)Ã—2 + (âˆ’1.5)Ã—3 + (âˆ’2.0)Ã—4]
      = 2/3 Ã— [âˆ’2.0 âˆ’ 4.5 âˆ’ 8.0]
      = 2/3 Ã— (âˆ’14.5)
      = âˆ’9.667
```

---

### Step 5: Compute Bias Gradient

```
âˆ‚L/âˆ‚B = 2/3 Ã— [Aâ‚ + Aâ‚‚ + Aâ‚ƒ]
      = 2/3 Ã— [âˆ’1.0 âˆ’ 1.5 âˆ’ 2.0]
      = 2/3 Ã— (âˆ’4.5)
      = âˆ’3.0
```

---

### Step 6: Update Parameters (with Î± = 0.01)

```
W_new = W âˆ’ Î± Ã— (âˆ‚L/âˆ‚W)
      = 1.5 âˆ’ 0.01 Ã— (âˆ’9.667)
      = 1.5 + 0.097
      = 1.597

B_new = B âˆ’ Î± Ã— (âˆ‚L/âˆ‚B)
      = 1.0 âˆ’ 0.01 Ã— (âˆ’3.0)
      = 1.0 + 0.03
      = 1.03
```

**Notice:** Both parameters **increased** because the gradients were **negative**, meaning we need to move in the positive direction to reduce the loss!

---

## ğŸ§® Why the Factor of 2?

You might wonder why we have `(2/n)` instead of just `(1/n)`.

### The Mathematical Reason:

When we take the derivative of the squared term:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                         â”‚
â”‚   d/dx[(Å· - y)Â²] = 2(Å· - y) Â· 1       â”‚
â”‚                  = 2(Å· - y)            â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The factor of 2 comes from the **power rule** in calculus:

```
d/dx(xÂ²) = 2x
```

### Does it Matter in Practice?

**No!** The factor of 2 doesn't significantly affect training because:

1. It's absorbed into the learning rate
2. If we use `(2/n)`, we might use learning rate `Î± = 0.01`
3. If we use `(1/n)`, we might use learning rate `Î± = 0.02`
4. The effect is the same!

Many implementations omit the factor of 2 for simplicity, but we include it here for **mathematical correctness**.

---

## ğŸ“ Key Insights

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                            â”‚
â”‚  1. Chain Rule is Fundamental                             â”‚
â”‚     â†’ Backpropagation = repeated chain rule application   â”‚
â”‚                                                            â”‚
â”‚  2. Error Signal: (Å·áµ¢ - yáµ¢)                               â”‚
â”‚     â†’ Represents how wrong our prediction is              â”‚
â”‚                                                            â”‚
â”‚  3. Input Scaling for Weight                              â”‚
â”‚     â†’ Multiply by xáµ¢ (input contribution)                 â”‚
â”‚                                                            â”‚
â”‚  4. Bias Simplicity                                       â”‚
â”‚     â†’ Doesn't depend on input (affects all equally)       â”‚
â”‚                                                            â”‚
â”‚  5. Averaging: (1/n) factor                               â”‚
â”‚     â†’ Ensures gradients don't grow with dataset size      â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Summary

### Weight Gradient Formula:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                             â•‘
â•‘   âˆ‚L/âˆ‚W = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢) Â· xáµ¢      â•‘
â•‘                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:** "How much does changing the weight affect the loss, weighted by the input values?"

---

### Bias Gradient Formula:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚B = 2/n Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)    â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:** "How much does changing the bias affect the loss, averaged across all samples?"

---

### Update Rules:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   W â† W - Î± Ã— (âˆ‚L/âˆ‚W)              â•‘
â•‘                                     â•‘
â•‘   B â† B - Î± Ã— (âˆ‚L/âˆ‚B)              â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Intuition:** "Move parameters in the direction that reduces the loss, scaled by the learning rate."

---

## ğŸ”— Connection to the Code

In our `SinglePerceptron` class, the `backward()` method implements these formulas:

```python
def backward(self, X, y_true, y_pred):
    n = tf.cast(tf.shape(X)[0], tf.float32)
    error = y_pred - y_true
    
    # Weight gradient: (2/n) Ã— Î£(error Ã— input)
    weight_grad = (2.0 / n) * tf.reduce_sum(error * X)
    
    # Bias gradient: (2/n) Ã— Î£(error)
    bias_grad = (2.0 / n) * tf.reduce_sum(error)
    
    return weight_grad, bias_grad
```

**This is the mathematical derivation brought to life in code!** ğŸ‰

---

## ğŸ¯ Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GRADIENT DESCENT FLOW                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1. Forward Pass:  Å·áµ¢ = WÂ·xáµ¢ + B                          â”‚
â”‚                                                             â”‚
â”‚  2. Compute Loss:  L = 1/n Ã— Î£(Å·áµ¢ - yáµ¢)Â²                  â”‚
â”‚                                                             â”‚
â”‚  3. Compute Gradients:                                      â”‚
â”‚     â€¢ âˆ‚L/âˆ‚W = 2/n Ã— Î£(Å·áµ¢ - yáµ¢)Â·xáµ¢                         â”‚
â”‚     â€¢ âˆ‚L/âˆ‚B = 2/n Ã— Î£(Å·áµ¢ - yáµ¢)                            â”‚
â”‚                                                             â”‚
â”‚  4. Update Parameters:                                      â”‚
â”‚     â€¢ W â† W - Î±Â·(âˆ‚L/âˆ‚W)                                    â”‚
â”‚     â€¢ B â† B - Î±Â·(âˆ‚L/âˆ‚B)                                    â”‚
â”‚                                                             â”‚
â”‚  5. Repeat until convergence                                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This is how a single perceptron learns through gradient descent! ğŸš€
