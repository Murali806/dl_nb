# Mathematical Derivation of Gradients for Three-Layer Neural Network with Activations

This document provides a step-by-step mathematical derivation of the backpropagation gradients for a **three-layer neural network with activation functions** (using tanh activations).

---

## âœ… Problem Setup

### Network Architecture (With Activation Functions)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚  Input (x) â†’ Layer 1 (tanh) â†’ Layer 2 (tanh) â†’ Layer 3 (linear) â†’ Å·  â”‚
â”‚                                                                         â”‚
â”‚  x â†’ [Wâ‚Â·x + bâ‚] â†’ tanh â†’ [Wâ‚‚Â·hâ‚ + bâ‚‚] â†’ tanh â†’ [Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ] â†’ Å·    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Notation

**Layer 1 (Hidden Layer 1 with tanh):**
- Weight: Wâ‚
- Bias: bâ‚
- Linear output: zâ‚ = Wâ‚Â·x + bâ‚
- Activation: hâ‚ = tanh(zâ‚)

**Layer 2 (Hidden Layer 2 with tanh):**
- Weight: Wâ‚‚
- Bias: bâ‚‚
- Linear output: zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
- Activation: hâ‚‚ = tanh(zâ‚‚)

**Layer 3 (Output Layer, no activation):**
- Weight: Wâ‚ƒ
- Bias: bâ‚ƒ
- Linear output: zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
- Output: Å· = zâ‚ƒ (no activation for regression)

---

## ğŸ¯ Forward Propagation

### Step-by-Step Computation

```
1. Layer 1:  zâ‚ = Wâ‚Â·x + bâ‚
             hâ‚ = tanh(zâ‚)

2. Layer 2:  zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
             hâ‚‚ = tanh(zâ‚‚)

3. Layer 3:  zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
             Å· = zâ‚ƒ
```

### Tanh Activation Function

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  tanh(x) = (eË£ - eâ»Ë£) / (eË£ + eâ»Ë£)            â”‚
â”‚                                                 â”‚
â”‚  Properties:                                    â”‚
â”‚  â€¢ Range: (-1, 1)                              â”‚
â”‚  â€¢ tanh(0) = 0                                 â”‚
â”‚  â€¢ Derivative: tanh'(x) = 1 - tanhÂ²(x)         â”‚
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Numerical Example

Let's use concrete numbers:
- **Input**: x = 2.0
- **Layer 1**: Wâ‚ = 0.5, bâ‚ = 0.1
- **Layer 2**: Wâ‚‚ = 0.8, bâ‚‚ = -0.2
- **Layer 3**: Wâ‚ƒ = 1.2, bâ‚ƒ = 0.3

**Forward Pass:**
```
zâ‚ = 0.5 Ã— 2.0 + 0.1 = 1.1
hâ‚ = tanh(1.1) â‰ˆ 0.8005

zâ‚‚ = 0.8 Ã— 0.8005 + (-0.2) = 0.4404
hâ‚‚ = tanh(0.4404) â‰ˆ 0.4139

zâ‚ƒ = 1.2 Ã— 0.4139 + 0.3 = 0.7967
Å· = 0.7967
```

If the true value is y = 4.0, then:
```
Error = Å· - y = 0.7967 - 4.0 = -3.2033
```

---

## ğŸ“‰ Loss Function

We use **Mean Squared Error (MSE)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   L = (1/n) Ã— Î£áµ¢â‚Œâ‚â¿ (Å·áµ¢ - yáµ¢)Â²    â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For a single sample:
```
L = (Å· - y)Â²
```

### Derivative of Loss with Respect to Output

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚Å· = 2(Å· - y)                 â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Å· = 2(0.7967 - 4.0) = 2(-3.2033) = -6.407
```

---

## ğŸ”„ Backpropagation: The Chain Rule

The key to backpropagation is the **chain rule** from calculus:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   For f(g(x)):                     â”‚
â”‚                                     â”‚
â”‚   df/dx = (df/dg) Ã— (dg/dx)        â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Difference from Linear Networks:**
Now we must include **activation function derivatives** in the chain!

---

## ğŸ“ Layer 3 Gradients (Output Layer)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ƒ and âˆ‚L/âˆ‚bâ‚ƒ

**Step 1**: We already have:
```
âˆ‚L/âˆ‚Å· = 2(Å· - y)
```

**Step 2**: Since Å· = zâ‚ƒ (no activation at output):
```
âˆ‚Å·/âˆ‚zâ‚ƒ = 1
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚ƒ = âˆ‚L/âˆ‚Å· Ã— âˆ‚Å·/âˆ‚zâ‚ƒ = 2(Å· - y) Ã— 1 = 2(Å· - y)
```

---

### Computing âˆ‚L/âˆ‚Wâ‚ƒ

**Step 4**: Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ = hâ‚‚
```

**Step 5**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚           â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Wâ‚ƒ = 2(0.7967 - 4.0) Ã— 0.4139
       = -6.407 Ã— 0.4139
       = -2.652
```

---

### Computing âˆ‚L/âˆ‚bâ‚ƒ

**Step 6**: Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ = 1
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚bâ‚ƒ = 2(0.7967 - 4.0) = -6.407
```

---

### Summary for Layer 3:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚           â•‘
â•‘                                     â•‘
â•‘   âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                â•‘
â•‘                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Note:** Same as linear network because output layer has no activation!

---

## ğŸ“ Layer 2 Gradients (Hidden Layer 2 with tanh)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚‚ and âˆ‚L/âˆ‚bâ‚‚

**Step 1**: We already have:
```
âˆ‚L/âˆ‚zâ‚ƒ = 2(Å· - y)
```

**Step 2**: Propagate gradient back to hâ‚‚. Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = Wâ‚ƒ
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚hâ‚‚ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ
```

**Step 4**: **KEY STEP** - Now we go through the tanh activation!

Since hâ‚‚ = tanh(zâ‚‚), we need the derivative of tanh:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚hâ‚‚/âˆ‚zâ‚‚ = tanh'(zâ‚‚) = 1 - tanhÂ²(zâ‚‚)     â”‚
â”‚                                             â”‚
â”‚   Since hâ‚‚ = tanh(zâ‚‚):                     â”‚
â”‚                                             â”‚
â”‚   âˆ‚hâ‚‚/âˆ‚zâ‚‚ = 1 - hâ‚‚Â²                        â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 5**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚‚ = âˆ‚L/âˆ‚hâ‚‚ Ã— âˆ‚hâ‚‚/âˆ‚zâ‚‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚L/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)      â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
1 - hâ‚‚Â² = 1 - (0.4139)Â² = 1 - 0.1713 = 0.8287

âˆ‚L/âˆ‚zâ‚‚ = 2(0.7967 - 4.0) Ã— 1.2 Ã— 0.8287
       = -6.407 Ã— 1.2 Ã— 0.8287
       = -6.361
```

---

### Computing âˆ‚L/âˆ‚Wâ‚‚

**Step 6**: Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = hâ‚
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚Wâ‚‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚ â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Wâ‚‚ = -6.361 Ã— 0.8005
       = -5.093
```

---

### Computing âˆ‚L/âˆ‚bâ‚‚

**Step 8**: Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚bâ‚‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)      â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚bâ‚‚ = -6.361
```

---

### Summary for Layer 2:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                             â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚ â•‘
â•‘                                             â•‘
â•‘   âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)      â•‘
â•‘                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Key Insight:** The term **(1 - hâ‚‚Â²)** is the tanh derivative!

---

## ğŸ“ Layer 1 Gradients (Hidden Layer 1 with tanh)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ and âˆ‚L/âˆ‚bâ‚

**Step 1**: We already have:
```
âˆ‚L/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)
```

**Step 2**: Propagate gradient back to hâ‚. Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚hâ‚ = Wâ‚‚
```

**Step 3**: By chain rule:
```
âˆ‚L/âˆ‚hâ‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚hâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚
```

**Step 4**: **KEY STEP** - Go through the tanh activation again!

Since hâ‚ = tanh(zâ‚):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   âˆ‚hâ‚/âˆ‚zâ‚ = tanh'(zâ‚) = 1 - tanhÂ²(zâ‚)     â”‚
â”‚                                             â”‚
â”‚   Since hâ‚ = tanh(zâ‚):                     â”‚
â”‚                                             â”‚
â”‚   âˆ‚hâ‚/âˆ‚zâ‚ = 1 - hâ‚Â²                        â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 5**: By chain rule:
```
âˆ‚L/âˆ‚zâ‚ = âˆ‚L/âˆ‚hâ‚ Ã— âˆ‚hâ‚/âˆ‚zâ‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                       â”‚
â”‚   âˆ‚L/âˆ‚zâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
1 - hâ‚Â² = 1 - (0.8005)Â² = 1 - 0.6408 = 0.3592

âˆ‚L/âˆ‚zâ‚ = -6.361 Ã— 0.8 Ã— 0.3592
       = -1.828
```

---

### Computing âˆ‚L/âˆ‚Wâ‚

**Step 6**: Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚Wâ‚ = x
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚Wâ‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚   âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚Wâ‚ = -1.828 Ã— 2.0
       = -3.656
```

---

### Computing âˆ‚L/âˆ‚bâ‚

**Step 8**: Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚bâ‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚bâ‚
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                       â”‚
â”‚   âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Numerical Example:**
```
âˆ‚L/âˆ‚bâ‚ = -1.828
```

---

### Summary for Layer 1:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘   âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x â•‘
â•‘                                                           â•‘
â•‘   âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)   â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Key Insight:** Both **(1 - hâ‚‚Â²)** and **(1 - hâ‚Â²)** appear - one for each tanh layer!

---

## ğŸ“Š Complete Gradient Summary

For a three-layer neural network **with tanh activations**:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘  OUTPUT LAYER (Layer 3, no activation):                      â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚                                     â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                                          â•‘
â•‘                                                               â•‘
â•‘  HIDDEN LAYER 2 (with tanh):                                 â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚                   â•‘
â•‘  âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)                        â•‘
â•‘                                                               â•‘
â•‘  HIDDEN LAYER 1 (with tanh):                                 â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x   â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)       â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Pattern Recognition:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Compared to LINEAR network:                                â”‚
â”‚                                                             â”‚
â”‚  â€¢ Each hidden layer adds a (1 - hÂ²) term                  â”‚
â”‚  â€¢ This is the tanh derivative                             â”‚
â”‚  â€¢ Output layer unchanged (no activation)                  â”‚
â”‚  â€¢ Gradients still flow backward through weights           â”‚
â”‚                                                             â”‚
â”‚  Key difference:                                            â”‚
â”‚  Linear:  Error Ã— Wâ‚ƒ Ã— Wâ‚‚                                  â”‚
â”‚  Tanh:    Error Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1-hâ‚Â²)            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Gradient Descent Update Rules

Once we have all gradients, we update parameters:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚   Wâ‚ƒ â† Wâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚ƒ)          â”‚
â”‚   bâ‚ƒ â† bâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚bâ‚ƒ)          â”‚
â”‚                                     â”‚
â”‚   Wâ‚‚ â† Wâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚‚)          â”‚
â”‚   bâ‚‚ â† bâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚‚)          â”‚
â”‚                                     â”‚
â”‚   Wâ‚ â† Wâ‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚)          â”‚
â”‚   bâ‚ â† bâ‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚)          â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Numerical Example (Î± = 0.01):

Using our computed gradients:

```
Wâ‚ƒ â† 1.2 - 0.01 Ã— (-2.652) = 1.2 + 0.027 = 1.227
bâ‚ƒ â† 0.3 - 0.01 Ã— (-6.407) = 0.3 + 0.064 = 0.364

Wâ‚‚ â† 0.8 - 0.01 Ã— (-5.093) = 0.8 + 0.051 = 0.851
bâ‚‚ â† -0.2 - 0.01 Ã— (-6.361) = -0.2 + 0.064 = -0.136

Wâ‚ â† 0.5 - 0.01 Ã— (-3.656) = 0.5 + 0.037 = 0.537
bâ‚ â† 0.1 - 0.01 Ã— (-1.828) = 0.1 + 0.018 = 0.118
```

---

## ğŸ“ Complete Numerical Example

Let's verify with a full forward and backward pass.

### Given:
- Input: x = 2.0
- True output: y = 4.0
- Initial parameters:
  - Wâ‚ = 0.5, bâ‚ = 0.1
  - Wâ‚‚ = 0.8, bâ‚‚ = -0.2
  - Wâ‚ƒ = 1.2, bâ‚ƒ = 0.3

### Forward Pass:

```
zâ‚ = 0.5 Ã— 2.0 + 0.1 = 1.1
hâ‚ = tanh(1.1) = 0.8005

zâ‚‚ = 0.8 Ã— 0.8005 + (-0.2) = 0.4404
hâ‚‚ = tanh(0.4404) = 0.4139

zâ‚ƒ = 1.2 Ã— 0.4139 + 0.3 = 0.7967
Å· = 0.7967
```

### Loss:

```
L = (Å· - y)Â² = (0.7967 - 4.0)Â² = (-3.2033)Â² = 10.261
```

### Backward Pass:

```
Error signal: 2(Å· - y) = 2(0.7967 - 4.0) = -6.407

Activation derivatives:
1 - hâ‚‚Â² = 1 - (0.4139)Â² = 0.8287
1 - hâ‚Â² = 1 - (0.8005)Â² = 0.3592

Layer 3:
âˆ‚L/âˆ‚Wâ‚ƒ = -6.407 Ã— 0.4139 = -2.652
âˆ‚L/âˆ‚bâ‚ƒ = -6.407

Layer 2:
âˆ‚L/âˆ‚zâ‚‚ = -6.407 Ã— 1.2 Ã— 0.8287 = -6.361
âˆ‚L/âˆ‚Wâ‚‚ = -6.361 Ã— 0.8005 = -5.093
âˆ‚L/âˆ‚bâ‚‚ = -6.361

Layer 1:
âˆ‚L/âˆ‚zâ‚ = -6.361 Ã— 0.8 Ã— 0.3592 = -1.828
âˆ‚L/âˆ‚Wâ‚ = -1.828 Ã— 2.0 = -3.656
âˆ‚L/âˆ‚bâ‚ = -1.828
```

### Update (Î± = 0.01):

```
Wâ‚ƒ = 1.2 - 0.01(-2.652) = 1.227
bâ‚ƒ = 0.3 - 0.01(-6.407) = 0.364

Wâ‚‚ = 0.8 - 0.01(-5.093) = 0.851
bâ‚‚ = -0.2 - 0.01(-6.361) = -0.136

Wâ‚ = 0.5 - 0.01(-3.656) = 0.537
bâ‚ = 0.1 - 0.01(-1.828) = 0.118
```

### Verify: Forward Pass with Updated Parameters

```
zâ‚ = 0.537 Ã— 2.0 + 0.118 = 1.192
hâ‚ = tanh(1.192) = 0.8310

zâ‚‚ = 0.851 Ã— 0.8310 + (-0.136) = 0.571
hâ‚‚ = tanh(0.571) = 0.5159

zâ‚ƒ = 1.227 Ã— 0.5159 + 0.364 = 0.997
Å· = 0.997
```

**New Loss:**
```
L = (0.997 - 4.0)Â² = (-3.003)Â² = 9.018
```

**Loss decreased from 10.261 to 9.018!** âœ… Gradient descent is working!

---

## ğŸ§® Batch Training

For multiple samples (batch size n), we average the gradients:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                   â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ƒ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— hâ‚‚áµ¢                            â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ƒ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢)                                   â•‘
â•‘                                                                   â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²) Ã— hâ‚áµ¢         â•‘
â•‘  âˆ‚L/âˆ‚bâ‚‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²)                â•‘
â•‘                                                                   â•‘
â•‘  âˆ‚L/âˆ‚Wâ‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1-hâ‚‚áµ¢Â²) Ã— Wâ‚‚ Ã— (1-hâ‚áµ¢Â²) Ã— xáµ¢ â•‘
â•‘  âˆ‚L/âˆ‚bâ‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1-hâ‚‚áµ¢Â²) Ã— Wâ‚‚ Ã— (1-hâ‚áµ¢Â²)  â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ¯ Key Insights

### 1. **Activation Functions Enable Non-linearity**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  With activations:                                      â”‚
â”‚  â€¢ Network can learn non-linear functions              â”‚
â”‚  â€¢ Cannot be collapsed to single layer                 â”‚
â”‚  â€¢ Each layer adds expressive power                    â”‚
â”‚                                                         â”‚
â”‚  Without activations (linear):                         â”‚
â”‚  â€¢ Can only learn linear functions                     â”‚
â”‚  â€¢ Equivalent to single layer                          â”‚
â”‚  â€¢ Multiple layers don't help                          â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Tanh Derivative: (1 - tanhÂ²(x))**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Properties of tanh derivative:                         â”‚
â”‚                                                         â”‚
â”‚  â€¢ Maximum value: 1 (when tanh(x) = 0)                 â”‚
â”‚  â€¢ Minimum value: 0 (when |tanh(x)| = 1)               â”‚
â”‚  â€¢ Always positive: 0 < (1 - tanhÂ²(x)) â‰¤ 1            â”‚
â”‚                                                         â”‚
â”‚  This means:                                            â”‚
â”‚  â€¢ Gradients are always scaled down (â‰¤ 1)              â”‚
â”‚  â€¢ Can lead to vanishing gradients in deep networks    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. **Gradient Flow with Activations**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Gradients flow backward:                               â”‚
â”‚                                                         â”‚
â”‚  Layer 3: Error signal                                  â”‚
â”‚  Layer 2: Error Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)                       â”‚
â”‚  Layer 1: Error Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)     â”‚
â”‚                                                         â”‚
â”‚  Each activation adds a (1 - hÂ²) term                  â”‚
â”‚  This can cause vanishing gradients!                   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. **Vanishing Gradient Problem**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Problem: Gradients get smaller in earlier layers      â”‚
â”‚                                                         â”‚
â”‚  Example:                                               â”‚
â”‚  If hâ‚ = 0.9, then (1 - hâ‚Â²) = 0.19                   â”‚
â”‚  If hâ‚‚ = 0.8, then (1 - hâ‚‚Â²) = 0.36                   â”‚
â”‚                                                         â”‚
â”‚  Layer 1 gradient âˆ 0.36 Ã— 0.19 = 0.068               â”‚
â”‚  â†’ Gradient is only 6.8% of original!                  â”‚
â”‚                                                         â”‚
â”‚  Solutions:                                             â”‚
â”‚  â€¢ Use ReLU instead of tanh                            â”‚
â”‚  â€¢ Batch normalization                                 â”‚
â”‚  â€¢ Residual connections                                â”‚
â”‚  â€¢ Careful weight initialization                       â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5. **Why Tanh Works for Shallow Networks**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                         â”‚
â”‚  Advantages:                                            â”‚
â”‚  â€¢ Zero-centered (helps with gradient flow)            â”‚
â”‚  â€¢ Smooth and differentiable everywhere                â”‚
â”‚  â€¢ Bounded output prevents exploding activations       â”‚
â”‚                                                         â”‚
â”‚  For 2-3 layer networks:                               â”‚
â”‚  â€¢ Vanishing gradient not severe                       â”‚
â”‚  â€¢ Good for learning smooth functions                  â”‚
â”‚  â€¢ Works well for regression tasks                     â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Comparison: Linear vs Tanh Network

### Gradient Formulas Side-by-Side:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  LINEAR NETWORK:                                                â”‚
â”‚  âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— Wâ‚‚ Ã— x                              â”‚
â”‚                                                                 â”‚
â”‚  TANH NETWORK:                                                  â”‚
â”‚  âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1-hâ‚Â²) Ã— x         â”‚
â”‚                                                                 â”‚
â”‚  Difference: Two (1 - hÂ²) terms for activation derivatives     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Numerical Comparison:

Using same weights but different architectures:

```
Linear Network:
âˆ‚L/âˆ‚Wâ‚ = -5.768 Ã— 1.2 Ã— 0.8 Ã— 2.0 = -11.078

Tanh Network:
âˆ‚L/âˆ‚Wâ‚ = -6.407 Ã— 1.2 Ã— 0.8287 Ã— 0.8 Ã— 0.3592 Ã— 2.0 = -3.656

Gradient is smaller in tanh network due to (1 - hÂ²) terms!
```

---

## ğŸ” Verification: Numerical Gradient Check

To verify your gradient implementation:

```python
def numerical_gradient(W, epsilon=1e-7):
    """
    Compute numerical gradient for weight W.
    """
    # Forward pass with W + epsilon
    W_plus = W + epsilon
    loss_plus = forward_and_compute_loss(W_plus, ...)
    
    # Forward pass with W - epsilon
    W_minus = W - epsilon
    loss_minus = forward_and_compute_loss(W_minus, ...)
    
    # Numerical gradient
    return (loss_plus - loss_minus) / (2 * epsilon)

# Compare with analytical gradient
numerical_grad = numerical_gradient(W1)
analytical_grad = compute_analytical_gradient()

print(f"Numerical: {numerical_grad}")
print(f"Analytical: {analytical_grad}")
print(f"Difference: {abs(numerical_grad - analytical_grad)}")
# Should be < 1e-7
```

---

## ğŸ’¡ Practical Tips

### 1. **Activation Function Choice**
```
â€¢ Tanh: Good for shallow networks, zero-centered
â€¢ ReLU: Better for deep networks, no vanishing gradient
â€¢ Sigmoid: Avoid (not zero-centered, vanishing gradient)
â€¢ Leaky ReLU: Prevents dead neurons
```

### 2. **Weight Initialization**
```
â€¢ Xavier/Glorot for tanh: W ~ N(0, âˆš(2/(n_in + n_out)))
â€¢ He initialization for ReLU: W ~ N(0, âˆš(2/n_in))
â€¢ Never initialize all weights to zero!
```

### 3. **Learning Rate**
```
â€¢ Start with Î± = 0.01 for tanh
â€¢ Monitor gradient magnitudes
â€¢ Use learning rate schedules
â€¢ Consider adaptive methods (Adam, RMSprop)
```

### 4. **Debugging Gradients**
```
â€¢ Check gradient magnitudes (should be ~0.001 to 0.1)
â€¢ Use numerical gradient checking
â€¢ Monitor activation statistics
â€¢ Watch for NaN or Inf values
```

### 5. **Preventing Vanishing Gradients**
```
â€¢ Use ReLU instead of tanh for deep networks
â€¢ Batch normalization
â€¢ Residual connections (skip connections)
â€¢ Gradient clipping
â€¢ Proper weight initialization
```

---

## ğŸ“ Summary

### The Complete Backpropagation Algorithm with Activations:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  1. FORWARD PASS:                                          â”‚
â”‚     â€¢ zâ‚ = Wâ‚Â·x + bâ‚                                      â”‚
â”‚     â€¢ hâ‚ = tanh(zâ‚)                                       â”‚
â”‚     â€¢ zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚                                     â”‚
â”‚     â€¢ hâ‚‚ = tanh(zâ‚‚)                                       â”‚
â”‚     â€¢ zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ                                     â”‚
â”‚     â€¢ Å· = zâ‚ƒ                                              â”‚
â”‚                                                             â”‚
â”‚  2. COMPUTE LOSS:                                          â”‚
â”‚     â€¢ L = (Å· - y)Â²                                        â”‚
â”‚                                                             â”‚
â”‚  3. BACKWARD PASS (Compute Gradients):                    â”‚
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚                             â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)                                  â”‚
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²) Ã— hâ‚             â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²)                  â”‚
â”‚     â€¢ âˆ‚L/âˆ‚Wâ‚ = 2(Å·-y) Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1-hâ‚Â²) Ã— x â”‚
â”‚     â€¢ âˆ‚L/âˆ‚bâ‚ = 2(Å·-y) Ã— Wâ‚ƒ Ã— (1-hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1-hâ‚Â²)    â”‚
â”‚                                                             â”‚
â”‚  4. UPDATE PARAMETERS:                                     â”‚
â”‚     â€¢ Wâ‚ƒ â† Wâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚ƒ)                             â”‚
â”‚     â€¢ bâ‚ƒ â† bâ‚ƒ - Î± Ã— (âˆ‚L/âˆ‚bâ‚ƒ)                             â”‚
â”‚     â€¢ Wâ‚‚ â† Wâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚‚)                             â”‚
â”‚     â€¢ bâ‚‚ â† bâ‚‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚‚)                             â”‚
â”‚     â€¢ Wâ‚ â† Wâ‚ - Î± Ã— (âˆ‚L/âˆ‚Wâ‚)                             â”‚
â”‚     â€¢ bâ‚ â† bâ‚ - Î± Ã— (âˆ‚L/âˆ‚bâ‚)                             â”‚
â”‚                                                             â”‚
â”‚  5. REPEAT until convergence                               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— Connection to Code

In Python/NumPy, the backward pass would look like:

```python
def backward_with_tanh(x, y, y_pred, h1, h2, z1, z2, W3, W2, learning_rate=0.01):
    """
    Compute gradients and update parameters for 3-layer network with tanh.
    """
    n = len(x)  # batch size
    
    # Error signal
    error = y_pred - y
    
    # Activation derivatives
    tanh_deriv_2 = 1 - h2**2  # (1 - tanhÂ²(zâ‚‚))
    tanh_deriv_1 = 1 - h1**2  # (1 - tanhÂ²(zâ‚))
    
    # Layer 3 gradients (no activation)
    dW3 = (2.0 / n) * np.sum(error * h2)
    db3 = (2.0 / n) * np.sum(error)
    
    # Layer 2 gradients (with tanh)
    dz2 = error * W3 * tanh_deriv_2
    dW2 = (2.0 / n) * np.sum(dz2 * h1)
    db2 = (2.0 / n) * np.sum(dz2)
    
    # Layer 1 gradients (with tanh)
    dz1 = dz2 * W2 * tanh_deriv_1
    dW1 = (2.0 / n) * np.sum(dz1 * x)
    db1 = (2.0 / n) * np.sum(dz1)
    
    # Update parameters
    W3 -= learning_rate * dW3
    b3 -= learning_rate * db3
    W2 -= learning_rate * dW2
    b2 -= learning_rate * db2
    W1 -= learning_rate * dW1
    b1 -= learning_rate * db1
    
    return W3, b3, W2, b2, W1, b1
```

---

## ğŸŒŸ Key Takeaways

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                               â•‘
â•‘  1. Activation functions enable non-linear learning          â•‘
â•‘                                                               â•‘
â•‘  2. Each activation adds its derivative to the gradient      â•‘
â•‘                                                               â•‘
â•‘  3. Tanh derivative: (1 - tanhÂ²(x))                          â•‘
â•‘                                                               â•‘
â•‘  4. Gradients can vanish in deep networks with tanh          â•‘
â•‘                                                               â•‘
â•‘  5. ReLU is often better for deep networks                   â•‘
â•‘                                                               â•‘
â•‘  6. Proper initialization is crucial                         â•‘
â•‘                                                               â•‘
â•‘  7. Understanding this is key to all deep learning!          â•‘
â•‘                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

**This is how backpropagation works in a three-layer neural network with activation functions!** ğŸ‰

The same principles extend to:
- Different activation functions (ReLU, sigmoid, etc.)
- Deeper networks (just keep adding layers)
- Different architectures (CNNs, RNNs, Transformers)
- Different loss functions (cross-entropy, etc.)

**Understanding this is the foundation for understanding modern deep learning!** ğŸš€
