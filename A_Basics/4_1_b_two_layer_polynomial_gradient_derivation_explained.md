# Gradient Derivation for Two-Layer Neural Network: Polynomial Approximation

This document provides a detailed mathematical derivation of the gradients used in backpropagation for the **two-layer neural network** that approximates polynomial functions (y = xÂ²).

## ğŸ“ Network Architecture

```
Input (x) â†’ Hidden Layer 1 (1 neuron + tanh) â†’ Hidden Layer 2 (1 neuron + tanh) â†’ Output (y)
```

### Mathematical Notation

- **Input**: x (scalar)
- **Layer 1**: 
  - Weight: Wâ‚, Bias: bâ‚
  - Linear: zâ‚ = Wâ‚Â·x + bâ‚
  - Activation: hâ‚ = tanh(zâ‚)
- **Layer 2**: 
  - Weight: Wâ‚‚, Bias: bâ‚‚
  - Linear: zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
  - Activation: hâ‚‚ = tanh(zâ‚‚)
- **Output Layer**: 
  - Weight: Wâ‚ƒ, Bias: bâ‚ƒ
  - Linear: zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
  - Output: Å· = zâ‚ƒ (no activation)

---

## ğŸ¯ Forward Propagation

### Step-by-Step Computation

1. **Layer 1 (Hidden Layer 1)**:
   ```
   zâ‚ = Wâ‚Â·x + bâ‚
   hâ‚ = tanh(zâ‚)
   ```

2. **Layer 2 (Hidden Layer 2)**:
   ```
   zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚
   hâ‚‚ = tanh(zâ‚‚)
   ```

3. **Output Layer**:
   ```
   zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ
   Å· = zâ‚ƒ
   ```

### Example with Numbers

Let's say:
- x = 2.0
- Wâ‚ = 0.5, bâ‚ = 0.1
- Wâ‚‚ = 0.8, bâ‚‚ = -0.2
- Wâ‚ƒ = 1.2, bâ‚ƒ = 0.3

**Forward Pass**:
```
zâ‚ = 0.5 Ã— 2.0 + 0.1 = 1.1
hâ‚ = tanh(1.1) â‰ˆ 0.8005

zâ‚‚ = 0.8 Ã— 0.8005 + (-0.2) = 0.4404
hâ‚‚ = tanh(0.4404) â‰ˆ 0.4139

zâ‚ƒ = 1.2 Ã— 0.4139 + 0.3 = 0.7967
Å· = 0.7967
```

If true value y = 4.0 (since xÂ² = 4), then error = 0.7967 - 4.0 = -3.2033

---

## ğŸ“‰ Loss Function

We use **Mean Squared Error (MSE)**:

```
L = (1/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢)Â²
```

For a single sample:
```
L = (Å· - y)Â²
```

### Derivative of Loss

```
âˆ‚L/âˆ‚Å· = 2(Å· - y)
```

For batch training with n samples:
```
âˆ‚L/âˆ‚Å· = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢)
```

---

## ğŸ”„ Backpropagation: Chain Rule Application

The key to backpropagation is the **chain rule** from calculus. We compute gradients layer by layer, moving backward from output to input.

### General Chain Rule

For a composite function f(g(x)):
```
df/dx = (df/dg) Ã— (dg/dx)
```

---

## ğŸ“ Layer 3 Gradients (Output Layer)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ƒ and âˆ‚L/âˆ‚bâ‚ƒ

**Step 1**: Derivative of loss with respect to output
```
âˆ‚L/âˆ‚Å· = 2(Å· - y)
```

**Step 2**: Since Å· = zâ‚ƒ (no activation):
```
âˆ‚Å·/âˆ‚zâ‚ƒ = 1
```

**Step 3**: Chain rule gives us:
```
âˆ‚L/âˆ‚zâ‚ƒ = âˆ‚L/âˆ‚Å· Ã— âˆ‚Å·/âˆ‚zâ‚ƒ = 2(Å· - y) Ã— 1 = 2(Å· - y)
```

**Step 4**: Now compute weight gradient. Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ = hâ‚‚
```

**Step 5**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚
```

**Step 6**: Compute bias gradient. Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ = 1
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ƒ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚bâ‚ƒ = 2(Å· - y) Ã— 1 = 2(Å· - y)
```

### Summary for Layer 3:
```
âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚
âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)
```

### Numerical Example:
Using our example where Å· = 0.7967, y = 4.0, hâ‚‚ = 0.4139:
```
âˆ‚L/âˆ‚Wâ‚ƒ = 2(0.7967 - 4.0) Ã— 0.4139 = 2(-3.2033) Ã— 0.4139 â‰ˆ -2.652
âˆ‚L/âˆ‚bâ‚ƒ = 2(0.7967 - 4.0) = -6.407
```

---

## ğŸ“ Layer 2 Gradients (Hidden Layer 2)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚‚ and âˆ‚L/âˆ‚bâ‚‚

**Step 1**: We already have âˆ‚L/âˆ‚zâ‚ƒ = 2(Å· - y)

**Step 2**: Compute how zâ‚ƒ depends on hâ‚‚. Since zâ‚ƒ = Wâ‚ƒÂ·hâ‚‚ + bâ‚ƒ:
```
âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = Wâ‚ƒ
```

**Step 3**: Chain rule to get gradient at hâ‚‚:
```
âˆ‚L/âˆ‚hâ‚‚ = âˆ‚L/âˆ‚zâ‚ƒ Ã— âˆ‚zâ‚ƒ/âˆ‚hâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ
```

**Step 4**: Now we need to go through the activation. Since hâ‚‚ = tanh(zâ‚‚):
```
âˆ‚hâ‚‚/âˆ‚zâ‚‚ = tanh'(zâ‚‚) = 1 - tanhÂ²(zâ‚‚) = 1 - hâ‚‚Â²
```

**Step 5**: Chain rule to get gradient at zâ‚‚:
```
âˆ‚L/âˆ‚zâ‚‚ = âˆ‚L/âˆ‚hâ‚‚ Ã— âˆ‚hâ‚‚/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)
```

**Step 6**: Compute weight gradient. Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = hâ‚
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚
```

**Step 8**: Compute bias gradient. Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)
```

### Summary for Layer 2:
```
âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚
âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)
```

### Numerical Example:
Using Å· = 0.7967, y = 4.0, Wâ‚ƒ = 1.2, hâ‚‚ = 0.4139, hâ‚ = 0.8005:
```
1 - hâ‚‚Â² = 1 - 0.4139Â² â‰ˆ 0.8287

âˆ‚L/âˆ‚Wâ‚‚ = 2(-3.2033) Ã— 1.2 Ã— 0.8287 Ã— 0.8005 â‰ˆ -5.093
âˆ‚L/âˆ‚bâ‚‚ = 2(-3.2033) Ã— 1.2 Ã— 0.8287 â‰ˆ -6.361
```

---

## ğŸ“ Layer 1 Gradients (Hidden Layer 1)

### Goal: Compute âˆ‚L/âˆ‚Wâ‚ and âˆ‚L/âˆ‚bâ‚

**Step 1**: We already have âˆ‚L/âˆ‚zâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)

**Step 2**: Compute how zâ‚‚ depends on hâ‚. Since zâ‚‚ = Wâ‚‚Â·hâ‚ + bâ‚‚:
```
âˆ‚zâ‚‚/âˆ‚hâ‚ = Wâ‚‚
```

**Step 3**: Chain rule to get gradient at hâ‚:
```
âˆ‚L/âˆ‚hâ‚ = âˆ‚L/âˆ‚zâ‚‚ Ã— âˆ‚zâ‚‚/âˆ‚hâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚
```

**Step 4**: Go through the activation. Since hâ‚ = tanh(zâ‚):
```
âˆ‚hâ‚/âˆ‚zâ‚ = tanh'(zâ‚) = 1 - tanhÂ²(zâ‚) = 1 - hâ‚Â²
```

**Step 5**: Chain rule to get gradient at zâ‚:
```
âˆ‚L/âˆ‚zâ‚ = âˆ‚L/âˆ‚hâ‚ Ã— âˆ‚hâ‚/âˆ‚zâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)
```

**Step 6**: Compute weight gradient. Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚Wâ‚ = x
```

**Step 7**: Apply chain rule:
```
âˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x
```

**Step 8**: Compute bias gradient. Since zâ‚ = Wâ‚Â·x + bâ‚:
```
âˆ‚zâ‚/âˆ‚bâ‚ = 1
```

**Step 9**: Apply chain rule:
```
âˆ‚L/âˆ‚bâ‚ = âˆ‚L/âˆ‚zâ‚ Ã— âˆ‚zâ‚/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)
```

### Summary for Layer 1:
```
âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x
âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)
```

### Numerical Example:
Using previous values plus Wâ‚‚ = 0.8, hâ‚ = 0.8005, x = 2.0:
```
1 - hâ‚Â² = 1 - 0.8005Â² â‰ˆ 0.3592

âˆ‚L/âˆ‚Wâ‚ = 2(-3.2033) Ã— 1.2 Ã— 0.8287 Ã— 0.8 Ã— 0.3592 Ã— 2.0 â‰ˆ -3.656
âˆ‚L/âˆ‚bâ‚ = 2(-3.2033) Ã— 1.2 Ã— 0.8287 Ã— 0.8 Ã— 0.3592 â‰ˆ -1.828
```

---

## ğŸ“Š Complete Gradient Summary

For a two-layer network approximating y = xÂ²:

### Output Layer (Layer 3):
```
âˆ‚L/âˆ‚Wâ‚ƒ = 2(Å· - y) Ã— hâ‚‚
âˆ‚L/âˆ‚bâ‚ƒ = 2(Å· - y)
```

### Hidden Layer 2:
```
âˆ‚L/âˆ‚Wâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— hâ‚
âˆ‚L/âˆ‚bâ‚‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²)
```

### Hidden Layer 1:
```
âˆ‚L/âˆ‚Wâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²) Ã— x
âˆ‚L/âˆ‚bâ‚ = 2(Å· - y) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚Â²)
```

---

## ğŸ”„ Gradient Descent Update

Once we have all gradients, we update parameters:

```
Wâ‚ƒ â† Wâ‚ƒ - Î± Ã— âˆ‚L/âˆ‚Wâ‚ƒ
bâ‚ƒ â† bâ‚ƒ - Î± Ã— âˆ‚L/âˆ‚bâ‚ƒ

Wâ‚‚ â† Wâ‚‚ - Î± Ã— âˆ‚L/âˆ‚Wâ‚‚
bâ‚‚ â† bâ‚‚ - Î± Ã— âˆ‚L/âˆ‚bâ‚‚

Wâ‚ â† Wâ‚ - Î± Ã— âˆ‚L/âˆ‚Wâ‚
bâ‚ â† bâ‚ - Î± Ã— âˆ‚L/âˆ‚bâ‚
```

Where Î± is the learning rate (e.g., 0.01).

### Numerical Example (Î± = 0.01):
```
Wâ‚ƒ â† 1.2 - 0.01 Ã— (-2.652) = 1.2 + 0.02652 = 1.227
bâ‚ƒ â† 0.3 - 0.01 Ã— (-6.407) = 0.3 + 0.06407 = 0.364

Wâ‚‚ â† 0.8 - 0.01 Ã— (-5.093) = 0.8 + 0.05093 = 0.851
bâ‚‚ â† -0.2 - 0.01 Ã— (-6.361) = -0.2 + 0.06361 = -0.136

Wâ‚ â† 0.5 - 0.01 Ã— (-3.656) = 0.5 + 0.03656 = 0.537
bâ‚ â† 0.1 - 0.01 Ã— (-1.828) = 0.1 + 0.01828 = 0.118
```

---

## ğŸ§® Batch Training

For multiple samples (batch size n), we average the gradients:

```
âˆ‚L/âˆ‚Wâ‚ƒ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— hâ‚‚áµ¢
âˆ‚L/âˆ‚bâ‚ƒ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢)

âˆ‚L/âˆ‚Wâ‚‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²) Ã— hâ‚áµ¢
âˆ‚L/âˆ‚bâ‚‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²)

âˆ‚L/âˆ‚Wâ‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚áµ¢Â²) Ã— xáµ¢
âˆ‚L/âˆ‚bâ‚ = (2/n) Ã— Î£áµ¢ (Å·áµ¢ - yáµ¢) Ã— Wâ‚ƒ Ã— (1 - hâ‚‚áµ¢Â²) Ã— Wâ‚‚ Ã— (1 - hâ‚áµ¢Â²)
```

---

## ğŸ¯ Key Insights

### 1. **Chain Rule is Essential**
Each gradient is computed by multiplying derivatives along the path from loss to parameter.

### 2. **Gradient Flow**
Gradients flow backward through:
- Loss â†’ Output â†’ Hidden2 â†’ Hidden1 â†’ Input
- Each layer multiplies by its local gradient

### 3. **Activation Derivatives**
The tanh derivative (1 - tanhÂ²(x)) appears in hidden layer gradients, enabling non-linear learning.

### 4. **Vanishing Gradients**
Notice how gradients for Wâ‚ and bâ‚ involve products of many terms. If these terms are small (<1), gradients can vanish, making learning slow for early layers.

### 5. **Why Two Layers Work**
- Layer 1 transforms input non-linearly
- Layer 2 combines features non-linearly
- Together they can approximate quadratic functions

---

## ğŸ“ Mathematical Properties

### Tanh Activation
```
tanh(x) = (eË£ - eâ»Ë£) / (eË£ + eâ»Ë£)

Properties:
- Range: (-1, 1)
- tanh(0) = 0
- tanh'(x) = 1 - tanhÂ²(x)
- Maximum derivative: 1 (at x=0)
```

### Why Tanh for Polynomial Approximation?
1. **Non-linearity**: Essential for learning curves
2. **Zero-centered**: Helps with gradient flow
3. **Smooth derivative**: Enables stable learning
4. **Bounded output**: Prevents exploding activations

---

## ğŸ” Verification

To verify your gradient implementation:

1. **Numerical Gradient Check**:
   ```
   âˆ‚L/âˆ‚W â‰ˆ [L(W + Îµ) - L(W - Îµ)] / (2Îµ)
   ```
   where Îµ is a small value (e.g., 1e-7)

2. **Compare with Analytical Gradient**:
   The difference should be < 1e-7

3. **Gradient Descent Test**:
   Loss should decrease over iterations

---

## ğŸ’¡ Practical Tips

1. **Initialize weights carefully**: Use Xavier/He initialization
2. **Normalize inputs**: Helps with gradient stability
3. **Monitor gradients**: Watch for vanishing/exploding gradients
4. **Learning rate**: Start with 0.01, adjust based on loss curve
5. **Batch size**: Larger batches give more stable gradients

---

**This derivation shows how backpropagation computes gradients through multiple layers, enabling neural networks to learn complex non-linear functions like y = xÂ²!**
